{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KVAv9U3jY7i"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-28 16:01:29.288604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-28 16:01:29.447395: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-02-28 16:01:29.484282: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-02-28 16:01:30.173373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-28 16:01:30.173432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-28 16:01:30.173439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (TextVectorization, Dense, MultiHeadAttention, LayerNormalization, \n",
        "                                     Layer, Embedding, Input, Dropout)\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZInpwbT0b5_"
      },
      "source": [
        "# Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TL_AUlpOjdXK"
      },
      "outputs": [],
      "source": [
        "FULL_VOCAB = 'abcdefghijklmnopqrstuvwxyz'\n",
        "SEQ_LEN = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mGjSyURTkHCd"
      },
      "outputs": [],
      "source": [
        "def dataset1(vocab_size=2, dataset_size=10000, seq_len=10, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after a the first character in the vocabulary (and nowhere else)\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.where(inputs == vocab[0], 1., 0.).astype(np.float32)  # 1 = space, 0 = no space\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs\n",
        "\n",
        "def dataset2(vocab_size=2, dataset_size=10000, seq_len=10, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after the combination of 1st->2nd character in the vocabulary (and nowhere else)\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.zeros_like(inputs, dtype=np.float32)\n",
        "  for i, example in enumerate(inputs):\n",
        "    previous_char = example[0]\n",
        "    for j, char in enumerate(example[1:]):\n",
        "      if (previous_char == vocab[0]) and (char == vocab[1]):  # 1 = space, 0 = no space\n",
        "        outputs[i, j+1] = 1.\n",
        "      previous_char = char\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs\n",
        "\n",
        "def dataset3(vocab_size=2, dataset_size=10000, seq_len=10, insert_space_every=3, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after a certain number of characters, no matter what the characters\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.zeros_like(inputs, dtype=np.float32)\n",
        "  outputs[:, np.arange(insert_space_every-1, outputs.shape[1], insert_space_every)] = 1.\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS-yF0l-kiKQ",
        "outputId": "714ddf78-7b07-40cc-d723-143a60fc582a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-28 16:01:32.442622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-28 16:01:35.506158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22296 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
            "2023-02-28 16:01:35.507452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22296 MB memory:  -> device: 1, name: GeForce RTX 3090, pci bus id: 0000:5e:00.0, compute capability: 8.6\n",
            "2023-02-28 16:01:35.508637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22296 MB memory:  -> device: 2, name: GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6\n",
            "2023-02-28 16:01:35.509887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22296 MB memory:  -> device: 3, name: GeForce RTX 3090, pci bus id: 0000:d8:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(100,), dtype=tf.float32, name=None))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATASET_FN = dataset2\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ohw3pdnhxmFe"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.shuffle(1000).batch(128)\n",
        "valid_ds = valid_ds.batch(128)\n",
        "test_ds = test_ds.batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pz1wrufzn43",
        "outputId": "52932f03-5f08-4e25-8bdd-a3517b902f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'bbbbabbbbabbbaaabaababaabbbabbbaaababbbaabaabaabaaabaaaabaaabbabbaaabbbbbbaaaaabaabaaabababaaaabbbaa'\n",
            " b'abaababaabaabaabbabbabbbaaaabababbbabbaababbbaaabababbaaabaaaabbbbbabbbbbbabbabbabbbbbbbbbbbbbaaaaab'\n",
            " b'bbbabbbaabbbabaaaabaaababbbbbbabaaabaaababaaaabbbbbabbabaaaabbaabaaabbbaabbaababbabbbbbaabaabbababbb'\n",
            " b'bbbbaababbababababbaaabbaabbbaaaaabbbbaaababbaaabbbbabaabaabbbabbbbaaabbaaaaababbbaababaaaaabaabaaaa'\n",
            " b'abbbbabababbaabbaababbbabbababababaaababbbbabaaaaaababbbbbaababaabaaaabaabaaaabbabbabbbababaaabaaaaa'\n",
            " b'bbbababaababbaaaabbaaabbabbbbbbababaabaaabbbaaaabbbaaabbbabbababbbbaabbabbbbabbabbbabbbaababbababaab'\n",
            " b'babaabaababaaaabbaaabbaababbbaaabaaababbbbbababbaabababbabbabaaabbabbaaaabbaaabaaaabbbabbbabaabaabab'\n",
            " b'babbababbbbabbaabbaababaaabaabbabbabbaabaabaabbabaaaabaabaaabbbaabbbbbbbabbbbaabbaabbabbabbbbaaabaab'\n",
            " b'aaaabaabbabbbbaabbbaabbbaaaaabaaaabbaaaabbaabbbbbbbbbbbbababbaaaabbbbaaaabaabaabbaabababbabbbbbbaabb'\n",
            " b'bbabbaaaaabbbabaaabbabbaaababbaaabbabbbaaaaaabbbabababbbbbbbaababaabbbbbababababbbbaaababbbaaababbba'\n",
            " b'baabbabbababaaabaababbbaabbbbaabaaabbbbaaaabaaaabbbabbbaabbbaaabaabbabaaabbabbbbbbbabbaababaaabbbaba'\n",
            " b'baaabaabbbaaabbaaaaabbabaabbababbabbbabbbababbbaaabbbbbbbbabbbababbabbbaaaaaaabbabbabaabaababaabbaaa'\n",
            " b'bbbbabbaabaaaaaaababaaaabbabbbbbbbbbbbbaababbaaabbbbbaabaaaaaabaabaabbbbbaaaaaababbbaabaaaabbbaababa'\n",
            " b'baaaabbabbabbbabbaababbababbababbbaabbabbbaaabababbbbabbaababbabababbabaabbaaaabaaabbaaaaababbabbbab'\n",
            " b'aabbbbbbaaaaabaabbbabbbababababaaabbbaababababbbbbaabbababbaaabababbbbabbaaababaaabbbabbbbabbaabbaba'\n",
            " b'baaabbbaaabaaabaababaaaaabbbbabbabababaababaaaabbbababaababaaababbabbbaababbbbbabaabaaaababaabbbbbbb'\n",
            " b'babbaababbabaabbbaaaaaaabbabaaabbbaabaabaabababbbabbabbbbabbabaabaaaaababaaaaabaaaabbbabaabbabaabbaa'\n",
            " b'aaaabbbaabaabbbbabbbabababaabaaaababaaabbababbbbaabbbababbabbabababbabbabbaaabaaabbbabaabbaaabababba'\n",
            " b'bbaaaaaaaaaabababababbabbbababbababbbaabaabbaabbaababbaaabbbbbabbababbaabbabbbaabaaaabbbabbabaaaabab'\n",
            " b'babaababbbbaaabbbaabbbabaabaabaaabaabbbabbbaaaabbabbbabbbbbbaabbbabbaaabbbbaaabaaaaabbaabaaaaaaabbab'\n",
            " b'ababbabbaabbbbababbbbbbbaaaaabbbbbababaaababaabbaababaaabaababbaaaaabaabaaaababbbababbbabbbabbbabbab'\n",
            " b'baaaabaaabaaaababbbaabbabbaabaaaaabaaabbbaabbabbbaaaabababababbabbabaabaabbbaababbabaabbababbbabbbbb'\n",
            " b'abbaabbaabbbbaaabbaabaaaabbaababaaaaaaaababababbaaaabbaaaaabbaababbaabaaabbbbbababaaaabbbaabbbbabbaa'\n",
            " b'aabbaababbaabbaaaabbabbbbbaabaaabababbaabaaabbaababaabbabbaaabaabbbbbbbbbabbbaabaaaaabaaaabbbabaaaaa'\n",
            " b'bbaabbaaaabbbaababbabaabbaaababaaaaaaaaaabababbbbabaaabbbbabbaababbaababbbbbaabbbbbaaaaaaababbaabbaa'\n",
            " b'aaababbaaaaaabbaaaabbbbbbababaaaaabaaababbabbababaaaababbbbababaabaaabaaaaaaaaaabbabbababbbbabbaaabb'\n",
            " b'abbababaabaabaaabaaaaabaabaaaabbaabbaaaaabaaababbaaaaabbaaabbaabaaabaabaabbbaabaabbabbaaabababaaabbb'\n",
            " b'ababbbaaabbbaaaaaaaaaabbbabaababbabbbaabbbaabbbababababbbbaaababbbabbabaaabbbbbbbbbababaaabbabaaabba'\n",
            " b'abaabaaaabbbbabbbbbabaabbbabbbbbaabbabbbbbbabbababbbaaaaaaaababaabaaabaaabbaabbaaaaabaaabbbbabbbabaa'\n",
            " b'bbbbaaabaaabaabaabaaababbbabbbaabbabbaabaabbabbbaabbbbaabbaaaaabbbbbabbbbaaaaabbabbbabaaabbaabaaaabb'\n",
            " b'baababbabbaababbbaabbbbbababbbbabbbabbaababbabaabbbbbbabbbbbabbbbabbabbabaaaabbbabaabbaaaaaaabaabaaa'\n",
            " b'abaaabbbbbababaaababaabaabababbabaaaabbbbbbaaabababaabbaabbaabaabaaaaaaaabaabbbabbbbabbbaaabbaaaaaba'\n",
            " b'aabbabbbbbababbaaababbbaabbabbbbababaabbaaaaabbbbaaabbbaaaabaabaabbaabaabaabbabbbabbbaaababaaaaaaaba'\n",
            " b'babbabbbabbabbabaabbbaabababbaabaabbbababbbbaababbbbabbbaabbbabbaabbaaababbbaaababaabbbbbbabaabaaabb'\n",
            " b'babbaaababaabaababbbaabbaabaabbbababbaaaaaabaabbbbabbabbbbbbbabbaabbbbabbaaaabaaabbbbabbaabbaabbaaaa'\n",
            " b'baaabbbaaabbbbbaaabbaaababbbbbabaabbaaaabbbbbbbabbbaaaabababbabaabbbbbbabbaabbabaababaabbabbabbbbabb'\n",
            " b'bababbababbbaabbaaabbbabbaaabaabbbaaaabbbbbabbbababbaabbaaabaaabbaabbbabbabaabaaababaaabaaaabaabbbbb'\n",
            " b'baabbaaabaaaabbabbababaabaaabbbbbabbaabaaabaabaaaaaabbabbbaabbbabbbbaaaaabaabbbabaaaabaaaaaabaababbb'\n",
            " b'babaabbabbaaabaaabbaaaaababbbbabaababababbbababbaabaabbbabbabaaaabbbbbbbbabaaaababaaaabaabbbbaaaaabb'\n",
            " b'baabbbbbaaaaaaaabbabbbaabbbaaaaabaababababbbabaaabbbaaabaabaaaaabbaaaaabbbababaabbbbabbbabbabaabaaaa'\n",
            " b'bbbbaabbbbbabababbbabaabbaabaabaabbaaabaaaabaaabbabbabaaabbaabbabbaabbaaaaabbbbbabbbabbbabbabaabaaba'\n",
            " b'babbababbabbbaaaaaaababaabbabaaababbaabbbbbabaaaabbaabbabbbabbbaaababaaaaaaaaabbaabbbaaabbabbbaabbbb'\n",
            " b'bbaaaaaababaabbbabaaabaaaaabbaabbaabbabbaaaaaaabbabbbaabbbabbabaaaababababbaaaaaaabababbaaaaaabbbbba'\n",
            " b'aabbbababbbaababbbaabaababbbbbbababababbbbaaaabababbbbbaababbababbbbaabbaaabbabaaababbbaabbaaabbbbbb'\n",
            " b'aabbbaaaababababbababbbaaaaaaaaabbabbaaaababbabbabbbbaaaabbabbbbabbbabbbbabaaaababaaaaabaababaaaabaa'\n",
            " b'aababbabaabaaaaabbabaabaabbbbaaababbbbaaaaabbaaaabbbabbbaaaababbaabbabbbbbbabaabbbaababbabbbaabaabba'\n",
            " b'baabbbababbbbabbabbabbbbbabbbaaaabaabbbbaaaabbabaabbbbbbbbbabbbabaabaaabbabbbbbaaabbbbbaabababbbbaaa'\n",
            " b'baaaababaaabaaabbaabbbbbbaaaabaabbabbbababbbbbbbbbbbabbaabbaabbabbbaababababaabbbbbaaabaababbbababbb'\n",
            " b'aaabbaaabbbabaaaaaabbbbabbaaaabbabaaababbaabaabbbabaaababaababbabaabababaabaabbabbaababaabbababbaaba'\n",
            " b'bbaaaababaaabbbaabaabaaaabbbbaabbbababaabaaababbbaaabbbaaabaaabbaaaaaababaabbbaaaabbbaabbbabaabbbaba'\n",
            " b'babbaababababaabababbbbaabababaababaaabbbabbbaaaababbbbbaabbbabbbaababbbabbabaaabaabbbbbbbabaaababab'\n",
            " b'aaaaaaaaaabbabaababbabaaaabbbaaababbaabaaabaabaabaabaabaabababaabaabbaaaabbbabaabbbaabaaaaabaaaaabba'\n",
            " b'babbbabbbaababbababaabaabbaabbbbbaababbabaaabbababbaabbaaaaaabaaabbbbababaababbbaababbbbaababbaabbaa'\n",
            " b'aababbbaabababaabaaaabaabbbabaababaabbbbababbaabbbbabaaabbaababbaabaabbaaabaaaaaaabbabbbababbbbbbaaa'\n",
            " b'abbbaaabbabbabbaaaaabbabbabbabbbbabbaabababbabaaaaaaaabaabaaabaabbaabbbaaaabbbabbaaabbabbbabaabaabbb'\n",
            " b'baabbbaaababaaababbbabbabbabbabbbabababbbabbbaabaaabbbbbbabbbabbbbaaabbbbbbbaaabaaaabaababbbaababaaa'\n",
            " b'bbbbabbaaaabaaababaaabababaabaaaabbbabbbbbbaababaabbbaababbbaabaaababaaabbbabaabaaaaaaabaabbababbabb'\n",
            " b'aabaabbbbabababbaabbbabaaabbbbabbaaaaaabbbbbbbababaaaabbbabaabaaaaaabbbaabbbaabbabaaaaaaabbbaaabaabb'\n",
            " b'baabaaaaababbabbaabbaabbbbabbaaaaaaabbaabbabbaaabbabbaaaaababbbaabaabaaabbaababaabbabbbabaabbbbabbab'\n",
            " b'baabababbabaabbabbaabaababaaababaabbbaabbbabbbaabaabbbbbaabbababbbaabbaaaababaabbabbbabaaababababbbb'\n",
            " b'babbbaaabbbaaabaaaabbaabaaaaaaaaaabbbbbaaababbaaababbaabaaaaaaabbbaabaabaabaabbbbbabbabbbababbbabbaa'\n",
            " b'ababaaaabbbabbbaabbaaabbbabbbbbbabaaaaaaabbaabbaaababaaaaaaabbbaaaabbabaabbabbbbabbaabbbaabbbaabaaaa'\n",
            " b'bbbbababbabaaabbabaaabbaaaabbbabaaaaaababababaabbbabbabababbababbabaaaaabbababbbaaabbbabbbabababbaab'\n",
            " b'aabaababbabbbbaaabbababaabbaabbbbaabbbbabaabababbabaaaaaabaabbabbaababbababaaabbbaaaabaaabaaabbababb'\n",
            " b'ababbbbabababaabbbbbbbbbbbabbaabbbabbbaababaaaabaababaabbaaabbaaaaaaababaaaaaaaaaabbababaaaabbbbbabb'\n",
            " b'bbabbbbbabbabbbbabbabbbbbbbbbaabbaabaabbaabbabbbababababbababbbbbabbabbabaaaabaaababaaaaaaabaaaaabaa'\n",
            " b'aaaaaabbaaabbbbaabbaabbbbbbaaaaababaabaabababaaabbabbbbbbbababaabaaaabaabaaabbabbabbbaabbabbbbbbaaab'\n",
            " b'bbbbaabbbaabbbabbabbbbabaaaabbabbbaaabbbaabbabaaabaaaaaaaabbaaaaaaabababbbabbabbbababbabbbaabaabbbba'\n",
            " b'abbababbbaabbbbabaaabbaabbbabbababaaaabbbaaabaaaabaaabbababaabbbbabbabaaaaababaaabbaabaaaabbabaabbbb'\n",
            " b'bbbbbabbbaababbbabbbbaabbbbbaabbbbbbababbaaababaabaaaaaabbaabaababbaaaaaaabababbbbaaabbabaaabaabaaab'\n",
            " b'bbbaabababaababaababbaabbaaaaaaaabababbbbabaabaaaaabbbabbbbbababbabaabbbaabbaabbabaaabababbababbbaba'\n",
            " b'baaabbabbabaabbaabbaabbbabaaabbaaabababbababaabaaababbabbbabbbbbabbaaaabbabababaabaababaabbbbaabbaab'\n",
            " b'bbaaabababbbbabbabbaaabaabababbaaaaaabbaaababaaaaabbabbabaaabaababaaabbbababaabbbabaaaabbabbbbbbbbaa'\n",
            " b'bbababbbababbbabbabbaaabababababababaaaaababaaabbabbaabbbbaaababbbbaaaaaaaaaaaabaabababaaabbbbbababb'\n",
            " b'ababbababaabaaaabbbabbabababababaaaaabbaaabaaabbbaaabbbabbbaaabbbaababaaabaaaaabbababbbabaabbaabbbab'\n",
            " b'baabaababbaababbaabbababbbabaabaaaaabbbabbabbbabbbbbbaabbbbbbbaaabababbaabbabbaaabbaabaabaaabbbbaabb'\n",
            " b'ababbbabbbaaabbaabaabbbbbabbaababbabbabaabbabbbbbbbaabbbbbbabbaaaaaabaabbbaabbbababbbaabbaabaabbaabb'\n",
            " b'babaabbaaaabababbaabbbabbabbbbabbaaaaaaaabbbabbaabaabbabbbbaabbbbababbabbaaaabaababbaaaaaabbbbaaabba'\n",
            " b'abbaabbbabaabbaababbbbbbbbbaaaababbbabbbbaababaabbabbaababaaaaaabbabbbbaaabaaababbbbaabababbbabbaaaa'\n",
            " b'abaaabbaaababaabaabbbaaaaabaaaaabbbaaaabaaaaabbbabbabbbbabaaaabbbbbbababbbbaabbbabbbaaaabbaaaaaaabab'\n",
            " b'abbbbbbaababbbbabbbaabbabbabbabaaaaabbbbbbbbbaaabbaabbabbbbbbbbbbaababaabbbaabbbbabaabbbbaaaaabaaaba'\n",
            " b'baabbabbababbaababbbbbbbbaabaabbbbaabbbbbaaabbabababbbbbaabbaaaaabaaabaabaaabaaababbabbbbabaaabbaaaa'\n",
            " b'baababbababbabaababbaababbababbaaababbbaabaababbbbabbbbbbaaaabaaaabaabaabaabaaaaabbabaabaababababbab'\n",
            " b'aabbabbaababbbaababbbabaabbbbbbabbbbababaababbabbababaabaaaababbaaabababaabaaabbabbbbbaaaabaaaaaaaba'\n",
            " b'bbabbbbbababbbbbbbbbabbbbbbbbbabaaaabbbbbaaabaaababbabbbbaaaaabbbabbaabbbbbaaaaaaaabbbbbaaaabbbaaaba'\n",
            " b'baaaabbabbbbbbabbbabbbbbbbaaaaababaabbbabbbbbbbbaaabbabbaaaababababababbaabbaaaaaababbbbbbbabbbabbaa'\n",
            " b'aaabbabbbaabbababababbaaabaabbaaabaabbbaabbbbbaaababaaabbbbabbaabbbabbaaabbaabbaaaaabaaabbabbaaabbab'\n",
            " b'aabbbbbbabbbbaaaabbbabbbabaabababbaabaabbbbbabbbabbabaababaaaaaaababbbbabaababbababbbabbbaabaababbab'\n",
            " b'abaabababbbaabbbbbbbbbababaaabaaaabbbbabaaabbbaabbaaaaaaabbaababbbbaaabbbabbabbbbaababbababbbaaabbbb'\n",
            " b'baaaababbbabbbaabbabbbababaaabbaabbbbbababbbabbababbaababaaabbbababbaabbabbbabbaabaababbaaabbaaababb'\n",
            " b'abbbaabbababaaaaaabbababbabaababbababaabbaabaaababbbbabaaaabbaaaaababbaaaabbbaaaababbbaababbbbbbbaab'\n",
            " b'aaabaaaaabaabaabbabbaabababbaaaabaaaabbabaababbbaaaaaabbaabaaabbaabbaabaaababbabbbababbababbbbabbbba'\n",
            " b'baaaabbbaabbaaaaaaabaabbaabbbbbbbabaababaabaabababbbbbbaaaabbbbababababaababbbbababbababbbbabaababba'\n",
            " b'abbabbabbaababaababbaaabbbbabbaabbbbbbbabbaabbaababaabbaabbbaaabbaaaabaaaaabaabaaaabbabbaaaaabbaaaab'\n",
            " b'abaaababbbbaaabbababbbabbbbbabbbaaaaaabaaaabababaabaabbbaaababbabababaabaababaabaabaaababbbaababbbaa'\n",
            " b'baabaaabbaaabaaaabaaaaaaaabaabaaabaaaabaaabaaaaaabaabbaaabaaaaaababaababbabbbbaaababbaaaaababaaabbba'\n",
            " b'aabababababbabababaaabbbabbbabbaabbaaaabbabaabbbabaaaababbaaaaababbabbbbaabbaaaaaabaabaaabababbababa'\n",
            " b'aabaabababaaababbbaabbbababbaabaaababaabbbbbbbbabbababbbbbabaaaaabbbbaaababbabbbbbbbbbbaaabbaabbbbba'\n",
            " b'baabaabbbbbababbbbaaaaababbbbaaaaabaaabbababbbbbabaababbbabbabaababbbaabbbaaababaabbbbbabbaaaaababba'\n",
            " b'bbabbbaaaaabbbaaabbabaababaabaaaaaaabbbabaabaaaaabababbbbbbbbbaabababaaababbabbbaabaaabababbaaabbaaa'\n",
            " b'aaababaaabbabaaabababbaabaabaabbabbaaaabbbaabbbababbbaaaabbbbbbbaaababababbabbabbaabbbaaaabbaababbba'\n",
            " b'ababbbaaabaaaaabababbaaababaaaabbbaaabaababbabbbaabbbbbabbbbbaabbbbababaabbbabbbbabbaabaabbbbaaabaab'\n",
            " b'bbabaaaaaaaabbbabbabaaababbaababaabbaaabbabbaaaabaabaabaababbaaaabbbbbbbbbabaababbbaabbbaababbaabaab'\n",
            " b'babbbaaaabbabbbaabbbbbbbbababbbbaabaaababbbbabbbaabbbaaaaaabbabaabbaabababaaabaababbbbaaaaaaabbbabbb'\n",
            " b'bbabbaababbaaabbaaaaabababbabbbabbbabbaaaabaababbbbbabaaaabaabaaaaaabaabbbaaaaababaabaaabbbabbaabaab'\n",
            " b'bbabbaaaaabaaabbbababaababaaabaabbbaaaabbaabbbabbabbbaabbabaabbabaabaaaabbbbaaaaabbbbaaababbbbaabbbb'\n",
            " b'babbbbabababaabbaaaabaaaaaabbbbbbababbbbbabbbaabbbabbabbbaaabbabbaaabababbbabaaaaaababbabbabaaababbb'\n",
            " b'aaaabbaaabbaabbabbaaaabbaaaaabbabbbabbbabababababbaaaabaaaaabaaaabaabbaaabbabaabbbbbbbbababaaaabbbab'\n",
            " b'aababababaabbbbbabbbbbaababbaabbabaaaababbabaaabaabaaabbbabaaababbbbbaabbababbabaabbbababbbabbabaabb'\n",
            " b'abaaaaabbabbbbaaababbabbbbbbaaababbaaabbbabbbababbabbabbaabbaabaaabbaaaaabbaaabbbaaaababbabbaabaabab'\n",
            " b'aabaababaabbabbbbababbbabbbabbaaaabbabbabbbbaabaaaabaaaabbababbbaaababaaaaaabbbbaabababbaabbabaaaaab'\n",
            " b'bbbabaabaabbaaaaabbaabbbbaabbabaaaaabbbbabbaaabbbabaaaabaabbabbbaabbbabbbbaabaababbabababbbbbbabbbab'\n",
            " b'abaaababbbaabbbabaabbabbabbbaabaababaaaaababaabbbabbabaaababbaaabbababaabbaaaabbbaabbbbaabaabbbbabbb'\n",
            " b'abaaaabbabbababaaaabaaaaaaabbabaaaabbbbabbaaababbbabbbabbaaabaabbbaabbbbaabaabbaabbabaabbababbbabbbb'\n",
            " b'aabaabaababbaababbbabbabbbbbaabababbbaaabbabbbbbbabbabbbabbaaabbbabbaabbababbaabbaaabaaabaababababaa'\n",
            " b'baaabaababaaabbbbabbbbbaaaaaabaaaaaabaaabbabbaabaaaabbbabbbaaaaaabbbaabaaaaabaaaababbabbbbbaabbaabaa'\n",
            " b'bbbabbabbbabbabbaabbbaaaaabaabbaaabbaaaababbabbabbabbbabaaaabaaabbaababbaaaaabbaababaaababaaabbbaaba'\n",
            " b'babaabaaaaaabbabbaababaaaabaaaaabaababaabaaabaaaabaabaaababbaaaaabaaaabbbabbbabaaaaababbbaaababbaaaa'\n",
            " b'abbbbaabbbabaaaabbababbbbaabbabbaabbbbabababbbabbbbbbbbabbaaabbbaababbbbabaaabbabbbbbaabababbabbbaab'\n",
            " b'aabbaabbbbababbbbaaaabaababbaabbbababbbabbbaabbaabbaaabaaababbaaabbbbaaabababaabbababaaaabbbaaabbbba'\n",
            " b'ababbaabaaaabbaabbaabbabaaabbabbaababbaabbaaaabaaaaabaaababaabbabbbaaabababaaaabaababbbaaabbabbabbab'\n",
            " b'bbaaabaabbbbbbaaabbbbbbbbabbbababaaaabbaaabbabbababaabababbbbaaabbbbaaabaabbbbbabbabbbbbaaaaaabbbbba'\n",
            " b'babbbabbabbabbaabbabbbbbbbbaaaaabaabaabbaaabbbaabaaabaabbbbbababababbabaabbabbbbbbbaabaaaabaababbaba'\n",
            " b'ababaabbabababbbbabbbbaabbababbabbbbaaaabbbbabbbbbaaaaaaabbbaabbaaaababbbbaababbbbbbaaabaabaabaababa'\n",
            " b'bbabaabababaaaabbababbbbbbaaabaaaabaabbbbaababaabbaabaabbaabbbbbbbbaabbbabaaaaaaaabbaaababaabbbababa'\n",
            " b'ababbaaabbbbbbbbbaaabbbbabbbababbbaababbbbbbbbbbaaababababaaabbabbbbbaabbaabbaaaabbabbabbbabbbbbbbbb'\n",
            " b'aaaaaaabbbabaaaabbaabbaababbbbabbbaaababaaaaabbabbbaabbbaababababbaaabaaaabaaaaabaaaaaaabbbbbaaabbba'\n",
            " b'bbbbaababaabbabbbbababbbababaaabaaabbbbbbabbaaaabbbababbbaabababbbbaabbabaaababababaabaaabbaaaaababb'], shape=(128,), dtype=string)\n",
            "[[0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1]\n",
            " [0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1]\n",
            " [0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0]\n",
            " [0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
            " [0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0]\n",
            " [0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
            " [0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1]\n",
            " [0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1]\n",
            " [0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0]\n",
            " [0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0]\n",
            " [0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0]\n",
            " [0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1]\n",
            " [0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
            " [0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0]\n",
            " [0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0]\n",
            " [0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0]\n",
            " [0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "for test_inputs, test_outputs in train_ds.take(1):\n",
        "  pass\n",
        "print(test_inputs)\n",
        "tf.print(test_outputs,summarize=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsZ0lQIN0W4s"
      },
      "source": [
        "# Build layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df--lFrGkjxd",
        "outputId": "5f995796-f096-41c0-d9d9-6a573db3cd5f"
      },
      "outputs": [],
      "source": [
        "textvectorization = TextVectorization(split='character')\n",
        "textvectorization.adapt(train_ds.map(lambda x, y: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb7_5T0ht2Xs",
        "outputId": "5595f8b8-c9ad-4d1f-bbe0-390c3dadbfce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', 'a', 'b']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textvectorization.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnymjZzb0llK",
        "outputId": "6eb37a99-c532-4592-9dd1-9437f1ffc824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 100), dtype=int64, numpy=\n",
              "array([[3, 3, 3, ..., 3, 2, 2],\n",
              "       [2, 3, 2, ..., 2, 2, 3],\n",
              "       [3, 3, 3, ..., 3, 3, 3],\n",
              "       ...,\n",
              "       [2, 3, 2, ..., 3, 3, 3],\n",
              "       [2, 2, 2, ..., 3, 3, 2],\n",
              "       [3, 3, 3, ..., 2, 3, 3]])>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "tv_out = textvectorization(test_inputs)\n",
        "tv_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KFT2Y9Ddt4ZP"
      },
      "outputs": [],
      "source": [
        "def positional_encodings(seq_len, d_model):\n",
        "    max_wavelength = 10000.\n",
        "\n",
        "    pos = np.arange(seq_len)\n",
        "    inx = np.arange(d_model)\n",
        "\n",
        "    I, P = np.meshgrid(inx, pos)\n",
        "    pe_even = np.sin(P / max_wavelength**(I/d_model))\n",
        "    pe_odd = np.cos(P / max_wavelength**(I/d_model))\n",
        "        \n",
        "    pe = np.zeros((seq_len, d_model))\n",
        "    pe[:, ::2] = pe_even[:, ::2]\n",
        "    pe[:, 1::2] = pe_odd[:, ::2]\n",
        "    return tf.constant(pe, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oI8sXtDNuG_q"
      },
      "outputs": [],
      "source": [
        "D_MODEL = 512\n",
        "MAX_TOKENS = textvectorization.vocabulary_size()  # includes padding and UNK tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kRdsdnURuUAf"
      },
      "outputs": [],
      "source": [
        "class InputEmbeddings(Layer):\n",
        "    \n",
        "    def __init__(self, d_model, pos_encodings, max_tokens, name='input_embeddings', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.pos_encodings = pos_encodings\n",
        "        self.embedding = Embedding(max_tokens, d_model, mask_zero=True)\n",
        "        \n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return self.embedding.compute_mask(inputs)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        n = tf.shape(inputs)[-1]\n",
        "        pos_encodings = self.pos_encodings[:n, :]\n",
        "        h = self.embedding(inputs)\n",
        "        return h + pos_encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZObgqA5IzkAw",
        "outputId": "a18a3e8c-2031-437f-a5ff-7c2cdb86c2f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 100, 512])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "input_embeddings = InputEmbeddings(D_MODEL, positional_encodings(SEQ_LEN, D_MODEL), MAX_TOKENS)\n",
        "emb_out = input_embeddings(tv_out)\n",
        "emb_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "naL4m-nDuYoq"
      },
      "outputs": [],
      "source": [
        "def get_attention_mask(mask=None):\n",
        "    if mask is None:\n",
        "        return None\n",
        "    mask1 = mask[:, :, None]\n",
        "    mask2 = mask[:, None, :]\n",
        "    return mask1 & mask2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t3SNe8Mhuj11"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(Layer):\n",
        "    \n",
        "    def __init__(self, num_heads, key_dim, d_model, ff_dim, name='encoder_block', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.supports_masking = True  # This will pass on any incoming mask\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.d_model = d_model\n",
        "        self.ff_dim = ff_dim\n",
        "        self.multihead_attention = MultiHeadAttention(num_heads, key_dim)\n",
        "        self.ff = Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(d_model)\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization()\n",
        "        self.layernorm2 = LayerNormalization()\n",
        "        \n",
        "    def call(self, inputs, mask=None):\n",
        "        attention_mask = get_attention_mask(mask)\n",
        "        h = self.multihead_attention(inputs, inputs, attention_mask=attention_mask)\n",
        "        h = self.layernorm1(inputs + h)\n",
        "        \n",
        "        h_ff = self.ff(h)\n",
        "        return self.layernorm2(h + h_ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Iuo1tT05L_",
        "outputId": "db1ed685-7206-4c07-9ae6-cf5f28000687"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-28 16:01:40.432610: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2023-02-28 16:01:41.271159: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 100, 512])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "encoder_block = EncoderBlock(num_heads=2, key_dim=16, d_model=D_MODEL, ff_dim=32)\n",
        "enc_block_out = encoder_block(emb_out)\n",
        "enc_block_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbhc4Kgu1Ft1",
        "outputId": "d531b939-dd3b-4842-d958-9b11e14e1bdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 100), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_block_out._keras_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tLnkz0aOunDr"
      },
      "outputs": [],
      "source": [
        "class ClassifierHead(Layer):\n",
        "\n",
        "  def __init__(self, d_model, dropout_rate, units, name='classifier_head', **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.supports_masking = True\n",
        "    self.d_model = d_model\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.units = units\n",
        "    self.dense1 = Dense(units, activation='relu')\n",
        "    self.dropout = Dropout(dropout_rate)\n",
        "    self.dense2 = Dense(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "    seq_len = tf.shape(inputs)[1]\n",
        "    h = self.dense1(inputs)\n",
        "    h = self.dropout(h)\n",
        "    h = self.dense2(h)\n",
        "    return tf.reshape(h, (batch_size, seq_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwNcg2ssu7xY",
        "outputId": "b837f19a-552e-461e-c63d-c85ececa3749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]\n",
            " ...\n",
            " [ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]], shape=(128, 100), dtype=bool)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 100])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "classifier_head = ClassifierHead(D_MODEL, dropout_rate=0.1, units=32)\n",
        "head_out = classifier_head(enc_block_out)\n",
        "print(head_out._keras_mask)\n",
        "head_out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkJBE8-D6CUP"
      },
      "source": [
        "# Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yyGB_3NM3z1c"
      },
      "outputs": [],
      "source": [
        "class Transformer(Model):\n",
        "\n",
        "  def __init__(self, d_model, seq_len, max_tokens, num_heads, key_dim, ff_dim, dropout_rate, units,\n",
        "               textvectorization, name='transformer', **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.d_model = d_model\n",
        "    self.seq_len = seq_len\n",
        "    self.max_tokens = max_tokens\n",
        "    self.num_heads = num_heads\n",
        "    self.key_dim = key_dim\n",
        "    self.ff_dim = ff_dim\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.units = units\n",
        "    self.textvectorization = textvectorization\n",
        "    self.input_embeddings = InputEmbeddings(d_model, positional_encodings(seq_len, d_model),\n",
        "                                            max_tokens)\n",
        "    self.encoder_block = EncoderBlock(num_heads=num_heads, key_dim=key_dim, d_model=d_model, ff_dim=ff_dim)\n",
        "    self.classifier_head = ClassifierHead(d_model, dropout_rate=dropout_rate, units=units)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    inputs, y_true = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(inputs)\n",
        "      loss = self.compiled_loss(y_true, y_pred, regularization_losses=self.losses)\n",
        "    grads = tape.gradient(loss, self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "    self.compiled_metrics.update_state(y_true, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics} \n",
        "\n",
        "  def test_step(self, data):\n",
        "    inputs, y_true = data\n",
        "    y_pred = self(inputs)\n",
        "    loss = self.compiled_loss(y_true, y_pred, regularization_losses=self.losses)\n",
        "    self.compiled_metrics.update_state(y_true, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics} \n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.textvectorization(inputs)\n",
        "    h = self.input_embeddings(h)\n",
        "    h = self.encoder_block(h)\n",
        "    h = self.classifier_head(h)\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCejkQS_u-M8",
        "outputId": "56d03f77-8938-476b-87de-83aa65bccd90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  multiple                 0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " input_embeddings (InputEmbe  multiple                 2048      \n",
            " ddings)                                                         \n",
            "                                                                 \n",
            " encoder_block (EncoderBlock  multiple                 4207108   \n",
            " )                                                               \n",
            "                                                                 \n",
            " classifier_head (Classifier  multiple                 515       \n",
            " Head)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,209,671\n",
            "Trainable params: 4,209,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# NOTE: Strictly speaking not identical architecture but should approach in number of params\n",
        "# Kevin's original had only one layer and introduces intermediate dense prior to classification\n",
        "\n",
        "NUM_HEADS = 3\n",
        "KEY_DIM = 512\n",
        "FF_DIM = 1028\n",
        "DROPOUT_RATE = 0.1\n",
        "UNITS = 1\n",
        "\n",
        "# transformer = Sequential([\n",
        "#     textvectorization,\n",
        "#     InputEmbeddings(D_MODEL, positional_encodings(SEQ_LEN, D_MODEL), MAX_TOKENS, input_shape=(SEQ_LEN,)),\n",
        "#     EncoderBlock(num_heads=2, key_dim=16, d_model=D_MODEL, ff_dim=32),\n",
        "#     ClassifierHead(D_MODEL, dropout_rate=0.1, units=20)\n",
        "# ])\n",
        "transformer = Transformer(D_MODEL, SEQ_LEN, MAX_TOKENS, NUM_HEADS, KEY_DIM, FF_DIM,\n",
        "                          DROPOUT_RATE, UNITS, textvectorization)\n",
        "_ = transformer(test_inputs)\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i1w9P6w1jb9",
        "outputId": "50fb4118-ecb1-4fa0-d174-fc7e55630215"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 100])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "transformer_out = transformer(test_inputs)\n",
        "transformer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RziHQfys1zPF",
        "outputId": "940aa7db-12ab-4e17-fb0e-812e7b6195cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 100), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_out._keras_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U1MdOQR3voyC"
      },
      "outputs": [],
      "source": [
        "def masked_binary_crossentropy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  y_true: shape (batch_size, seq_len). 1. = no space, 2. = space\n",
        "  y_pred: shape (batch_size, seq_len, 1). Logits\n",
        "  \"\"\"\n",
        "  labels = y_true  # 0 = no space, 1 = space\n",
        "\n",
        "  # Deal with Keras 'feature' that squeezes out the last dimension silently (WTF)\n",
        "  # if tf.shape(y_pred)[-1] == 1:  \n",
        "  #   logits = tf.squeeze(y_pred, axis=-1)  # (batch_size, seq_len)\n",
        "  # else:\n",
        "  logits = y_pred\n",
        "  probs = tf.nn.sigmoid(logits)\n",
        "  bce = - labels * tf.math.log(probs) - ((1 - labels) * tf.math.log(1 - probs))\n",
        "\n",
        "  return tf.reduce_mean(bce)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQllI6hc2TXe",
        "outputId": "0374f3d9-bd49-469d-8874-96597950d805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.6231091>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "masked_binary_crossentropy(test_outputs, transformer_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMrac9fG8DGi",
        "outputId": "037bff38-52de-4423-d104-ded7c6eea3f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.62175703>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for test_inputs, test_outputs in train_ds.take(1):\n",
        "  y_pred = transformer(test_inputs)\n",
        "  loss = masked_binary_crossentropy(test_outputs, y_pred)\n",
        "\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWyMnokQxbq4",
        "outputId": "e2b320a3-bc02-4857-a771-8a2ef7d60fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 8s 69ms/step - loss: 0.7247 - binary_accuracy: 0.7523 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2477 - val_loss: 0.6762 - val_binary_accuracy: 0.7525 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2475\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 5s 58ms/step - loss: 0.6677 - binary_accuracy: 0.7523 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2477 - val_loss: 0.6592 - val_binary_accuracy: 0.7525 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2475\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 5s 59ms/step - loss: 0.6517 - binary_accuracy: 0.7523 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2477 - val_loss: 0.6442 - val_binary_accuracy: 0.7525 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2475\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "\n",
        "earlystopping = EarlyStopping(patience=2, monitor=\"val_binary_accuracy\")\n",
        "transformer.compile(loss=masked_binary_crossentropy, optimizer='adam',\n",
        "                    metrics=[BinaryAccuracy(), Precision(), Recall(), AUC(curve='PR')])\n",
        "\n",
        "history = transformer.fit(train_ds, validation_data=valid_ds, epochs=20, callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQgPCkRf72zt",
        "outputId": "81df67f0-e887-44c2-eb44-8a6d7c72d7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 2s 22ms/step - loss: 0.6442 - binary_accuracy: 0.7525 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2475\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'loss': 0.644208550453186,\n",
              " 'binary_accuracy': 0.7525280117988586,\n",
              " 'precision': 0.0,\n",
              " 'recall': 0.0,\n",
              " 'auc': 0.24747200310230255}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbMJx_s-_-ln",
        "outputId": "0501e219-83ef-4fae-9995-06a06bcce6c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[-0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748,\n",
              "        -0.2170748, -0.2170748, -0.2170748, -0.2170748, -0.2170748]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer(['ababab'+'b'*(SEQ_LEN-6)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AcBR0pFKBUP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf_210",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "4c2409f7cd36a60864259fe7c86cc6f7edd5e2a0604f36f600c4aba8b227f5d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
