{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KVAv9U3jY7i"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-02 14:55:12.474241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 14:55:12.641910: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-02 14:55:12.680060: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-03-02 14:55:13.435912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-02 14:55:13.436010: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-02 14:55:13.436017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (TextVectorization, Dense, MultiHeadAttention, LayerNormalization, \n",
        "                                     Layer, Embedding, Input, Dropout)\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (TextVectorization, Dense, MultiHeadAttention, LayerNormalization, \n",
        "                                     Layer, Embedding, Input, Dropout)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import logging\n",
        "\n",
        "GPU_FROM = 0\n",
        "GPU_TO = 1  \n",
        "\n",
        "visible_devices = tf.config.get_visible_devices('GPU')\n",
        "logging.info(f\"Num GPUs visible:{len(visible_devices)}\")\n",
        "tf.config.set_visible_devices(visible_devices[GPU_FROM:GPU_TO],'GPU')\n",
        "\n",
        "visible_devices = tf.config.get_visible_devices('GPU')\n",
        "logging.info(f\"Num GPUs to be used: {len(visible_devices)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZInpwbT0b5_"
      },
      "source": [
        "# Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TL_AUlpOjdXK"
      },
      "outputs": [],
      "source": [
        "FULL_VOCAB = 'abcdefghijklmnopqrstuvwxyz'\n",
        "SEQ_LEN = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mGjSyURTkHCd"
      },
      "outputs": [],
      "source": [
        "def dataset1(vocab_size=2, dataset_size=10000, seq_len=10, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after a the first character in the vocabulary (and nowhere else)\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.where(inputs == vocab[0], 1., 0.).astype(np.float32)  # 1 = space, 0 = no space\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs\n",
        "\n",
        "def dataset2(vocab_size=2, dataset_size=10000, seq_len=10, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after the combination of 1st->2nd character in the vocabulary (and nowhere else)\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.zeros_like(inputs, dtype=np.float32)\n",
        "  for i, example in enumerate(inputs):\n",
        "    previous_char = example[0]\n",
        "    for j, char in enumerate(example[1:]):\n",
        "      if (previous_char == vocab[0]) and (char == vocab[1]):  # 1 = space, 0 = no space\n",
        "        outputs[i, j+1] = 1.\n",
        "      previous_char = char\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs\n",
        "\n",
        "def dataset3(vocab_size=2, dataset_size=10000, seq_len=10, insert_space_every=3, full_vocab=FULL_VOCAB):\n",
        "  \"\"\"\n",
        "  Inserts a space after a certain number of characters, no matter what the characters\n",
        "  \"\"\"\n",
        "  assert vocab_size > 1\n",
        "  vocab = list(full_vocab[:vocab_size])\n",
        "  inputs = np.random.choice(vocab, size=(dataset_size, seq_len))\n",
        "  outputs = np.zeros_like(inputs, dtype=np.float32)\n",
        "  outputs[:, np.arange(insert_space_every-1, outputs.shape[1], insert_space_every)] = 1.\n",
        "  concatenated_inputs = np.array([''.join(row) for row in inputs])\n",
        "  return concatenated_inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS-yF0l-kiKQ",
        "outputId": "714ddf78-7b07-40cc-d723-143a60fc582a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-02 14:55:15.406265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 14:55:16.217637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22296 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(10,), dtype=tf.float32, name=None))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATASET_FN = dataset2\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(DATASET_FN(vocab_size=2, seq_len=SEQ_LEN))\n",
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ohw3pdnhxmFe"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.shuffle(1000).batch(128)\n",
        "valid_ds = valid_ds.batch(128)\n",
        "test_ds = test_ds.batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pz1wrufzn43",
        "outputId": "52932f03-5f08-4e25-8bdd-a3517b902f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'aababbbaaa' b'abbbaaabbb' b'ababbabaab' b'babaaaaaaa' b'baabababab'\n",
            " b'bbbbbbbbaa' b'aaabbbbbbb' b'bbabaaaaab' b'babaaaaaab' b'bbabbaabaa'\n",
            " b'abbaabbbbb' b'bbbbbbabaa' b'aaabbaaabb' b'bbabbbaaab' b'aaabbbbabb'\n",
            " b'aaabababbb' b'ababaaaaaa' b'abababbaaa' b'babbabbbaa' b'bbaaaabbab'\n",
            " b'aabbbbabaa' b'baabababab' b'bbbababbab' b'aaaaaabbbb' b'baabaaabaa'\n",
            " b'abbbaabbaa' b'bbbaaaabbb' b'bbabbbaaaa' b'bbbaabbaab' b'abaaabbbba'\n",
            " b'babababaab' b'bbbbaaaaab' b'bbaaaababa' b'babbbbabba' b'ababbbabba'\n",
            " b'bbbabbbbba' b'abaababbab' b'baaaabbbba' b'bbabbabbbb' b'bbaaaababb'\n",
            " b'abbabbaabb' b'bbbbbbabbb' b'baaaabbbba' b'abbababbba' b'ababbaaaba'\n",
            " b'bbabaababa' b'abbaaabaab' b'aaaaaaabbb' b'bbbbaaaaaa' b'bababababb'\n",
            " b'baaabbbaab' b'aaabbaabaa' b'babbaabbbb' b'aabbbbbbaa' b'aababababa'\n",
            " b'baaaaabbaa' b'baaaabbbba' b'babaabbaab' b'bbbabbbbbb' b'bababbbaab'\n",
            " b'abaaaaabba' b'abbabbbbaa' b'aaabaabbba' b'abaabbbaba' b'aabaabaaaa'\n",
            " b'aabbaabbbb' b'babaaaabba' b'aaaaaababa' b'babbbaaaaa' b'abaaabaabb'\n",
            " b'aababaaaaa' b'baaaabbaba' b'bbbabaaaba' b'bbbabbbbaa' b'aaabaaaaab'\n",
            " b'aaaaaabaaa' b'bbbaaaaaaa' b'aabaabbbaa' b'babaaabbaa' b'aababbbbaa'\n",
            " b'baaabbbbbb' b'babbbaaaab' b'aaaabbabab' b'abaabbbabb' b'bbbaababaa'\n",
            " b'abbaabbbbb' b'bbbbaabbab' b'bbbbbbbaab' b'bbbaabbbba' b'aabbbabaaa'\n",
            " b'bbaaabaaab' b'baabbbaabb' b'baabbabaaa' b'abaabbbaba' b'bbabbaaabb'\n",
            " b'abbbabbbba' b'aabbaaabaa' b'bbabaabbba' b'bbaaabbbaa' b'abbbbabbab'\n",
            " b'bbabbabaab' b'babbaabaab' b'aaaabbbbba' b'aaaaaababb' b'aabababaab'\n",
            " b'bbabbbbabb' b'bababbaaab' b'bbaaabaaaa' b'abaabbabba' b'baabababbb'\n",
            " b'bbbbbbaaba' b'babbbbbbba' b'aabbabbaab' b'baaaaabbab' b'bbbabababa'\n",
            " b'abbabaabbb' b'babbbbbaaa' b'ababbabaab' b'aabbbbaaaa' b'aabaabbbaa'\n",
            " b'abbababbab' b'aaababaabb' b'abbbabbbaa' b'babaabbabb' b'babababbaa'\n",
            " b'bbbabbbbba' b'babbbbaaba' b'aaabaaaabb'], shape=(128,), dtype=string)\n",
            "[[0 0 1 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 1 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 1 0 1 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 1 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 0 1 0 1]\n",
            " [0 0 0 0 1 0 1 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 1]\n",
            " [0 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 1 0 1 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 1 0 0 0 0 1 0 0]\n",
            " [0 1 0 1 0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 1 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0]\n",
            " [0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0 1 0]\n",
            " [0 1 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 1 0 1 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 1 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 1 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1 0 0 1 0]\n",
            " [0 0 1 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 1 0 1]\n",
            " [0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 1 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 1 0 1 0 1 0]\n",
            " [0 1 0 0 1 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 1 0 0 1 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 1 0 0 1]\n",
            " [0 0 0 1 0 1 0 0 1 0]\n",
            " [0 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "for test_inputs, test_outputs in train_ds.take(1):\n",
        "  pass\n",
        "print(test_inputs)\n",
        "tf.print(test_outputs,summarize=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsZ0lQIN0W4s"
      },
      "source": [
        "# Build layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Embedding defn\n",
        "def positional_encoding(length, depth):\n",
        "    \"\"\"\n",
        "    Generates a matrix following:\n",
        "    $$\n",
        "        PE_{pos,i} = trig(\\frac{pos, 10000^{\\frac{i, d}})\n",
        "    $$\n",
        "    where d is the dimensionality of the output embedding and the position\n",
        "    is defined absolutely (from 0).\n",
        "    \"\"\"\n",
        "    per_trig_d_model = depth/2\n",
        "    \n",
        "\n",
        "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "    depths = np.arange(per_trig_d_model)[np.newaxis, :]/per_trig_d_model   # (1, depth/2)\n",
        "    angle_rates = 1 / (10000**depths)         # (1, depth/2)\n",
        "    angle_rads = positions * angle_rates      # (seq, depth/2)\n",
        "\n",
        "    pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)], # (seq, depth)\n",
        "      axis=-1) \n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PostionalEmbedding(tf.keras.layers.Layer):\n",
        "    # TODO: FIX spelling\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size, \n",
        "            d_model, \n",
        "            max_seq_len,\n",
        "            pos_multiplier=1, \n",
        "            mask_zero=True):\n",
        "        \"\"\"\n",
        "        Generate a layer to embed input tokens that are already int-encoded\n",
        "         through a lookup embedding and positional information \n",
        "         (through additive positional embeddings as in Vaswani 2017).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=mask_zero) \n",
        "        self.pos_encoding = positional_encoding(length=max_seq_len, depth=d_model)\n",
        "        self.supports_masking = True\n",
        "        self.pos_multiplier = pos_multiplier\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # Assumes (batch, seq_len) int-encoded inputs\n",
        "        x = self.embedding(x) # (batch, seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # TODO: try running without this\n",
        "        x = x + self.pos_multiplier*self.pos_encoding[tf.newaxis, :, :] # new axis for batch dimension - try without\n",
        "        return x\n",
        "\n",
        "def point_wise_feed_forward_network(\n",
        "    d_model, # Input/output dimensionality.\n",
        "    dff # Inner-layer dimensionality.\n",
        "    ):\n",
        "\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # Shape `(batch_size, seq_len, dff)`.\n",
        "      tf.keras.layers.Dense(d_model)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self,*,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               dropout_rate=0.1,\n",
        "               **kwargs\n",
        "               ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "\n",
        "        # Multi-head self-attention.\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_attention_heads,\n",
        "            key_dim=d_model, # Size of each attention head for query Q and key K.\n",
        "            dropout=dropout_rate, # TODO: maybe dropout?\n",
        "            )\n",
        "        # Point-wise feed-forward network.\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        # Layer normalization.\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Dropout for the point-wise feed-forward network.\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        # A boolean mask.\n",
        "        if mask is not None:\n",
        "            mask1 = mask[:, :, None] # (B, seq, 1)\n",
        "            mask2 = mask[:, None, :] # (B, 1, seq)\n",
        "            attention_mask = mask1 & mask2 \n",
        "            # For each element in the sequence - what other elements can it attend to\n",
        "            # only defined in this simple self-cartesion product because we are\n",
        "            # simply attempting to mask away unused token slots for efficiency\n",
        "            # Has block strucure, NOT upper triangular like a causal mask would\n",
        "        else:\n",
        "            attention_mask = None\n",
        "\n",
        "        # Multi-head self-attention output (`tf.keras.layers.MultiHeadAttention `).\n",
        "        attn_output = self.mha(\n",
        "            query=x,  # Query Q tensor.\n",
        "            value=x,  # Value V tensor.\n",
        "            key=x,  # Key K tensor.\n",
        "            attention_mask=attention_mask, # A boolean mask that prevents attention to certain positions.\n",
        "            training=training, # A boolean indicating whether the layer should behave in training mode.\n",
        "            )\n",
        "\n",
        "        # Multi-head self-attention output after layer normalization and a residual/skip connection.\n",
        "        out1 = self.layernorm1(x + attn_output)  # Shape `(batch_size, input_seq_len, d_model)`\n",
        "\n",
        "        # Point-wise feed-forward network output.\n",
        "        ffn_output = self.ffn(out1)  # Shape `(batch_size, input_seq_len, d_model)`\n",
        "        ffn_output = self.dropout1(ffn_output, training=training) # TODO: try removing dropout errywhere\n",
        "        # Point-wise feed-forward network output after layer normalization and a residual skip connection.\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "\n",
        "        return out2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "               *,\n",
        "               num_layers,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               tokenizer, # int-mode tokenizer for input text,\n",
        "               seq_len,\n",
        "               dropout_rate=0.1,\n",
        "               pos_multiplier=1 \n",
        "               ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Tokenization\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Embeddings + Positional encoding\n",
        "        self.pos_embedding = PostionalEmbedding(tokenizer.vocabulary_size(), d_model, seq_len, pos_multiplier=pos_multiplier)\n",
        "\n",
        "        # Encoder layers.\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(\n",
        "              d_model=d_model,\n",
        "              num_attention_heads=num_attention_heads,\n",
        "              dff=dff,\n",
        "              dropout_rate=dropout_rate,\n",
        "              name=f\"encoder_sublayer_{i}\")\n",
        "            for i in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def compute_mask(self, x, previous_mask=None):\n",
        "        x = self.tokenizer(x)\n",
        "        return self.pos_embedding.compute_mask(x, previous_mask)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        # Sum up embeddings and positional encoding.\n",
        "        x = self.tokenizer(x)\n",
        "        mask = self.pos_embedding.compute_mask(x)\n",
        "        # TODO: why am i giving back the mask here?\n",
        "        # FIXME: Remove pointless mask passing\n",
        "        x = self.pos_embedding(x, mask=mask)  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "        # Add dropout.\n",
        "        # ?\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # N encoder layers.\n",
        "        for i in range(self.num_layers):\n",
        "            # TODO: Do not need to pass mask \n",
        "            # TODO: Check mask propagation\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # Shape `(batch_size, input_seq_len, d_model)`.\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "               *,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               dropout_rate=0.1,\n",
        "               **kwargs\n",
        "               ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Masked multi-head self-attention.\n",
        "        self.mha_masked = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_attention_heads,\n",
        "            key_dim=d_model, # Size of each attention head for query Q and key K.\n",
        "            dropout=dropout_rate\n",
        "        )\n",
        "        # Multi-head cross-attention.\n",
        "        self.mha_cross = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_attention_heads,\n",
        "            key_dim=d_model, # Size of each attention head for query Q and key K.\n",
        "            dropout=dropout_rate\n",
        "        )\n",
        "\n",
        "        # Point-wise feed-forward network.\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        # Layer normalization.\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Dropout for the point-wise feed-forward network.\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask, enc_output, enc_mask, training):\n",
        "        # The encoder output shape is `(batch_size, input_seq_len, d_model)`.\n",
        "\n",
        "        # A boolean mask.\n",
        "        self_attention_mask = None\n",
        "        if mask is not None:\n",
        "            mask1 = mask[:, :, None]\n",
        "            mask2 = mask[:, None, :]\n",
        "            self_attention_mask = mask1 & mask2\n",
        "\n",
        "        # Masked multi-head self-attention output (`tf.keras.layers.MultiHeadAttention`).\n",
        "        attn_masked, attn_weights_masked = self.mha_masked(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            attention_mask=self_attention_mask,  # A boolean mask that prevents attention to certain positions.\n",
        "            use_causal_mask=True,  # A boolean to indicate whether to apply a causal mask to prevent tokens from attending to future tokens.\n",
        "            return_attention_scores=True,  # Shape `(batch_size, target_seq_len, d_model)`.\n",
        "            training=training  # A boolean indicating whether the layer should behave in training mode.\n",
        "            )\n",
        "\n",
        "        # Masked multi-head self-attention output after layer normalization and a residual/skip connection.\n",
        "        self_attn = self.layernorm1(attn_masked + x)\n",
        "\n",
        "        # A boolean mask.\n",
        "        attention_mask = None\n",
        "        if mask is not None and enc_mask is not None:\n",
        "            mask1 = mask[:, :, None]\n",
        "            mask2 = enc_mask[:, None, :]\n",
        "            attention_mask = mask1 & mask2\n",
        "\n",
        "        # Multi-head cross-attention output (`tf.keras.layers.MultiHeadAttention `).\n",
        "        attn_cross, attn_weights_cross = self.mha_cross(\n",
        "            query=enc_output,\n",
        "            key=self_attn,\n",
        "            value=self_attn,\n",
        "            attention_mask=attention_mask,  # A boolean mask that prevents attention to certain positions.\n",
        "            return_attention_scores=True,  # Shape `(batch_size, num_queries, d_model)`.\n",
        "            training=training  # A boolean indicating whether the layer should behave in training mode.\n",
        "        )\n",
        "\n",
        "        # Multi-head cross-attention output after layer normalization and a residual/skip connection.\n",
        "        out2 = self.layernorm2(attn_cross + self_attn)  # (batch_size, source_seq_len, d_model)\n",
        "\n",
        "        # Point-wise feed-forward network output.\n",
        "        ffn_output = self.ffn(out2)  # Shape `(batch_size, source_seq_len, d_model)`.\n",
        "        ffn_output = self.dropout1(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # Shape `(batch_size, source_seq_len, d_model)`.\n",
        "\n",
        "        return out3\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    output_tokens = [0, 1, 2]   # We only have a 3 token output language - space, no space, no text\n",
        "\n",
        "    def __init__(self,\n",
        "               *,\n",
        "               num_layers,\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               seq_len,\n",
        "               dropout_rate=0.1\n",
        "               ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PostionalEmbedding(len(Decoder.output_tokens), d_model, seq_len)\n",
        "\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(\n",
        "              d_model=d_model,\n",
        "              num_attention_heads=num_attention_heads,\n",
        "              dff=dff,\n",
        "              dropout_rate=dropout_rate,\n",
        "              name=f\"decoder_sublayer_{i}\")\n",
        "            for i in range(num_layers)\n",
        "        ]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    \n",
        "    def compute_mask(self, x, previous_mask=None):\n",
        "        x = self.tokenizer(x)\n",
        "        return self.pos_embedding.compute_mask(x, previous_mask)\n",
        "\n",
        "    def call(self, dec_input, enc_output, enc_mask, training):\n",
        "        mask = self.pos_embedding.compute_mask(dec_input)\n",
        "        x = self.pos_embedding(dec_input)  # Shape: `(batch_size, target_seq_len, d_model)`.\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x  = self.dec_layers[i](x, mask, enc_output, enc_mask, training)\n",
        "\n",
        "        # The shape of x is `(batch_size, target_seq_len, d_model)`.\n",
        "        return x\n",
        "\n",
        "class SpaceSegmentationTransformer(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Transformer for finding space in english text without spaces\n",
        "\n",
        "    Encoder takes in batches of strings, decoder takes in batches of seq_len\n",
        "    tokens indicating space or not.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "               *,\n",
        "               num_layers, # Number of decoder layers.\n",
        "               d_model, # Input/output dimensionality.\n",
        "               num_attention_heads,\n",
        "               dff, # Inner-layer dimensionality.\n",
        "               input_tokenizer,\n",
        "               seq_len,\n",
        "               dropout_rate=0.1,\n",
        "               classification_threshold=0.5,\n",
        "               num_classes=2,\n",
        "               pos_multiplier=1,\n",
        "               ):\n",
        "        super().__init__()\n",
        "        d_model = d_model + 1 if d_model % 2 == 1 else d_model # Ensure even dimensionality so our positional encodings work\n",
        "        self.encoder = Encoder(\n",
        "          num_layers=num_layers,\n",
        "          d_model=d_model,\n",
        "          num_attention_heads=num_attention_heads,\n",
        "          dff=dff,\n",
        "          tokenizer=input_tokenizer,\n",
        "          dropout_rate=dropout_rate,\n",
        "          seq_len=seq_len,\n",
        "          pos_multiplier=pos_multiplier\n",
        "          )\n",
        "        self.tokenizer = input_tokenizer\n",
        "        self.dense = tf.keras.layers.Dense(num_classes)  # Why does softmax here break it?\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Expects inputs of text to be segmentated and, if training, segmentation\n",
        "        labels aligned to input text - where 2 indicates space, 1 indicates \n",
        "        no space and 0 indicates a missing character (essentially end token).\n",
        "\n",
        "        Assumes batch first ranks\n",
        "        \"\"\"\n",
        "        to_enc = inputs\n",
        "        run_sequential = False\n",
        "\n",
        "        if not training:\n",
        "            # This is where we will migrate sequential generation once we re-include the decoder\n",
        "            batch_size = tf.shape(to_enc)[0]\n",
        "            to_dec = tf.zeros((batch_size, 1))\n",
        "            run_sequential = True\n",
        "\n",
        "        \n",
        "        # The encoder output.\n",
        "        enc_output = self.encoder(to_enc, training)  # `(batch_size, inp_seq_len, d_model)`\n",
        "        # enc_mask = self.encoder.compute_mask(to_enc)\n",
        "        return tf.reshape(self.dense(enc_output), [tf.shape(inputs)[0], SEQ_LEN])\n",
        "\n",
        "class LossWithVoids(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Class to intercept any loss calculations when we want to ensure 'void'\n",
        "    tokens in y_true are not included in loss calculations\n",
        "    \"\"\"\n",
        "    def __init__(self, loss: tf.keras.losses.Loss, void_tokens: list, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss = loss\n",
        "        self.void_tokens = void_tokens\n",
        "\n",
        "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "        mask = tf.cast(tf.ones_like(y_true), tf.bool)\n",
        "        for token in self.void_tokens:\n",
        "            mask &= tf.not_equal(y_true, token) # (Batch, seq_len)\n",
        "        return self.loss.__call__(y_true[mask], y_pred[mask]) \n",
        "\n",
        "class WarmupSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return 2* tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkJBE8-D6CUP"
      },
      "source": [
        "# Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.layers.TextVectorization(\n",
        "    output_sequence_length=SEQ_LEN,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"character\",\n",
        "    output_mode=\"int\",\n",
        ")\n",
        "tokenizer.adapt(train_ds.take(10).map(lambda x,y: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yyGB_3NM3z1c"
      },
      "outputs": [],
      "source": [
        "NUM_HEADS = 2\n",
        "KEY_DIM = 16\n",
        "FF_DIM = 32\n",
        "DROPOUT_RATE = 0.1\n",
        "UNITS = 20\n",
        "\n",
        "transformer = SpaceSegmentationTransformer(\n",
        "    seq_len=SEQ_LEN,\n",
        "    num_layers=1,\n",
        "    d_model=32,\n",
        "    num_attention_heads=NUM_HEADS,\n",
        "    dff=FF_DIM,\n",
        "    input_tokenizer=tokenizer,\n",
        "    num_classes=1,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i1w9P6w1jb9",
        "outputId": "50fb4118-ecb1-4fa0-d174-fc7e55630215"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-02 14:55:19.189906: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 10])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "transformer_out = transformer(test_inputs)\n",
        "transformer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RziHQfys1zPF",
        "outputId": "940aa7db-12ab-4e17-fb0e-812e7b6195cb"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformer_out\u001b[39m.\u001b[39;49m_keras_mask\n",
            "File \u001b[0;32m/disk1/al3615/tf_210/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mravel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    439\u001b[0m   \u001b[39m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    440\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    443\u001b[0m \u001b[39m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[39m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[0;32m--> 446\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'"
          ]
        }
      ],
      "source": [
        "transformer_out._keras_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U1MdOQR3voyC"
      },
      "outputs": [],
      "source": [
        "def masked_binary_crossentropy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  y_true: shape (batch_size, seq_len). 1. = no space, 2. = space\n",
        "  y_pred: shape (batch_size, seq_len, 1). Logits\n",
        "  \"\"\"\n",
        "  labels = y_true  # 0 = no space, 1 = space\n",
        "\n",
        "  # Deal with Keras 'feature' that squeezes out the last dimension silently (WTF)\n",
        "  # if tf.shape(y_pred)[-1] == 1:  \n",
        "  #   logits = tf.squeeze(y_pred, axis=-1)  # (batch_size, seq_len)\n",
        "  # else:\n",
        "  logits = y_pred\n",
        "  probs = tf.nn.sigmoid(logits)\n",
        "  bce = - labels * tf.math.log(probs) - ((1 - labels) * tf.math.log(1 - probs))\n",
        "\n",
        "  return tf.reduce_mean(bce)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQllI6hc2TXe",
        "outputId": "0374f3d9-bd49-469d-8874-96597950d805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5822634>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test\n",
        "\n",
        "masked_binary_crossentropy(test_outputs, transformer_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMrac9fG8DGi",
        "outputId": "037bff38-52de-4423-d104-ded7c6eea3f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5924214>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for test_inputs, test_outputs in train_ds.take(1):\n",
        "  y_pred = transformer(test_inputs)\n",
        "  loss = masked_binary_crossentropy(test_outputs, y_pred)\n",
        "\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWyMnokQxbq4",
        "outputId": "e2b320a3-bc02-4857-a771-8a2ef7d60fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 4s 30ms/step - loss: 0.3694 - binary_accuracy: 0.7913 - precision: 0.6296 - recall: 0.1876 - auc: 0.4344 - val_loss: 0.2833 - val_binary_accuracy: 0.8321 - val_precision: 0.7254 - val_recall: 0.4164 - val_auc: 0.6149\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.2675 - binary_accuracy: 0.8506 - precision: 0.7440 - recall: 0.5170 - auc: 0.6447 - val_loss: 0.1904 - val_binary_accuracy: 0.8986 - val_precision: 0.8510 - val_recall: 0.6698 - val_auc: 0.7873\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.1903 - binary_accuracy: 0.9071 - precision: 0.8386 - recall: 0.7299 - auc: 0.7797 - val_loss: 0.1038 - val_binary_accuracy: 0.9645 - val_precision: 0.8934 - val_recall: 0.9577 - val_auc: 0.9307\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.1387 - binary_accuracy: 0.9385 - precision: 0.8925 - recall: 0.8275 - auc: 0.8498 - val_loss: 0.0415 - val_binary_accuracy: 0.9971 - val_precision: 1.0000 - val_recall: 0.9873 - val_auc: 1.0000\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.1084 - binary_accuracy: 0.9531 - precision: 0.9198 - recall: 0.8684 - auc: 0.8859 - val_loss: 0.0230 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0929 - binary_accuracy: 0.9605 - precision: 0.9330 - recall: 0.8894 - auc: 0.9028 - val_loss: 0.0148 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0827 - binary_accuracy: 0.9653 - precision: 0.9393 - recall: 0.9053 - auc: 0.9162 - val_loss: 0.0109 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "\n",
        "earlystopping = EarlyStopping(patience=2, monitor=\"val_binary_accuracy\")\n",
        "transformer.compile(loss=masked_binary_crossentropy, optimizer='adam',\n",
        "                    metrics=[BinaryAccuracy(), Precision(), Recall(), AUC(curve='PR')])\n",
        "\n",
        "history = transformer.fit(train_ds, validation_data=valid_ds, epochs=20, callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQgPCkRf72zt",
        "outputId": "81df67f0-e887-44c2-eb44-8a6d7c72d7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0109 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'loss': 0.01093901228159666,\n",
              " 'binary_accuracy': 1.0,\n",
              " 'precision': 1.0,\n",
              " 'recall': 1.0,\n",
              " 'auc': 1.0}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbMJx_s-_-ln",
        "outputId": "0501e219-83ef-4fae-9995-06a06bcce6c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[-8.061153 ,  6.1619864, -8.910204 ,  4.308545 , -8.751168 ,\n",
              "         4.4881577, -3.1239035, -6.4980745, -6.1512465, -4.930309 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "transformer(['ababab'+'b'*(SEQ_LEN-6)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AcBR0pFKBUP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
