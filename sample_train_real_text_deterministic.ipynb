{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:02:59.255537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 13:02:59.402622: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-25 13:02:59.439124: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-25 13:03:00.091460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 13:03:00.091517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 13:03:00.091523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "GPU_FROM = 2\n",
    "GPU_TO = 3  \n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs visible:{len(visible_devices)}\")\n",
    "tf.config.set_visible_devices(visible_devices[GPU_FROM:GPU_TO],'GPU')\n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs to be used: {len(visible_devices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/a/al3615/tf_210/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-25 13:03:04.939111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 13:03:05.599221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22296 MB memory:  -> device: 2, name: GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"AMDDebutsDual-CoreOpteronProcessorAMD'snewdual-coreOpteronchipisdesignedmainlyforcorporatecomputingapplications,includingdatabases,Webservices,andfinancialtransactions.\", shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:03:06.491126: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import html\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from segmentation.model import SpaceSegmentationTransformer\n",
    "from segmentation.model import LossWithVoids\n",
    "\n",
    "gap = 3\n",
    "len = 100\n",
    "\n",
    "punc_mapping = {ord(x):x for x in string.punctuation}\n",
    "entity_mapping = {f\" ?{k}\": v for k, v in html.entities.html5.items() if k.endswith(\";\") and v in string.punctuation}\n",
    "punc_mapping = {f' ?&?#?{k};': v for k, v in punc_mapping.items()}\n",
    "\n",
    "train, test = tfds.load('ag_news_subset', split=\"train\"), tfds.load('ag_news_subset', split=\"test\")\n",
    "\n",
    "def unescape(text):\n",
    "    for match, replace in punc_mapping.items():\n",
    "        text = tf.strings.regex_replace(text, match, replace)\n",
    "    for match, replace in entity_mapping.items():#\n",
    "        text = tf.strings.regex_replace(text, match, replace)\n",
    "    return text\n",
    "\n",
    "def join_title_desc(text_dict):\n",
    "    return text_dict['title'] + ' ' + text_dict['description']\n",
    "\n",
    "def remove_space(text):\n",
    "    return tf.strings.reduce_join(tf.strings.strip(tf.strings.split(text)), axis=-1)\n",
    "\n",
    "def space_after_letter(letter):\n",
    "    def replacer(x):\n",
    "        x = tf.strings.regex_replace(x, f\"({letter})\", r\"\\1 \") # add whitespace back in after every letter e\n",
    "        return x\n",
    "    return replacer\n",
    "\n",
    "train = train.map(join_title_desc).map(unescape).map(remove_space)\n",
    "test = test.map(join_title_desc).map(unescape).map(remove_space)\n",
    "\n",
    "for x in train.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(), dtype=string, numpy=b\"amddebutsdual-coreopteronprocessoramd'snewdual-coreopteronchipisdesignedmainlyforcorporatecomputinga\">, None), <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       2., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
      "       1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
      "       1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:03:06.925195: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_labels(text):\n",
    "    text = tf.strings.substr(text, 0, 100)\n",
    "    text = tf.strings.lower(text)\n",
    "    encoder_in = text\n",
    "    encoder_out = tf.strings.regex_replace(text, r\"[^e]\", \"1\") # 1 indicates character\n",
    "    encoder_out = tf.strings.regex_replace(encoder_out, r\"e\", \"2\") # 2 indicates space\n",
    "    encoder_out = tf.strings.bytes_split(encoder_out)\n",
    "    encoder_out = tf.strings.to_number(encoder_out)\n",
    "    encoder_out = tf.pad(encoder_out, [[0,100-tf.shape(encoder_out)[0]]])\n",
    "\n",
    "    return (encoder_in, None), encoder_out\n",
    "\n",
    "train = train.map(generate_labels)\n",
    "val = test.map(generate_labels)\n",
    "for x in train.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:03:09.956188: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'e',\n",
       " 'a',\n",
       " 't',\n",
       " 's',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 'h',\n",
       " 'c',\n",
       " 'u',\n",
       " 'p',\n",
       " 'm',\n",
       " 'f',\n",
       " 'g',\n",
       " 'b',\n",
       " 'y',\n",
       " 'w',\n",
       " 'k',\n",
       " 'v',\n",
       " '-',\n",
       " ',',\n",
       " '.',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '0',\n",
       " 'x',\n",
       " 'j',\n",
       " '2',\n",
       " '1',\n",
       " 'q',\n",
       " '&',\n",
       " ':',\n",
       " 'z',\n",
       " '4',\n",
       " '3',\n",
       " '\\\\',\n",
       " '5',\n",
       " '\"',\n",
       " '<',\n",
       " '>',\n",
       " '/',\n",
       " '7',\n",
       " '6',\n",
       " '$',\n",
       " '8',\n",
       " '9',\n",
       " ';',\n",
       " '?',\n",
       " '=',\n",
       " '#',\n",
       " '!',\n",
       " '*']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=100,\n",
    "    standardize=\"lower\",\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "\n",
    "tokenizer.adapt(train.take(1000).map(lambda x,y: x[0]))\n",
    "tokenizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(), dtype=string, numpy=b\"amddebutsdual-coreopteronprocessoramd'snewdual-coreopteronchipisdesignedmainlyforcorporatecomputinga\">, None), <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       2., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
      "       1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
      "       1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>)\n",
      "tf.Tensor(\n",
      "[ 3 16 11 11  2 19 14  4  5 11 14  3 10 24 13  6  9  2  6 15  4  2  9  6\n",
      "  8 15  9  6 13  2  5  5  6  9  3 16 11 27  5  8  2 21 11 14  3 10 24 13\n",
      "  6  9  2  6 15  4  2  9  6  8 13 12  7 15  7  5 11  2  5  7 18  8  2 11\n",
      " 16  3  7  8 10 20 17  6  9 13  6  9 15  6  9  3  4  2 13  6 16 15 14  4\n",
      "  7  8 18  3], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[False False False False  True False False False False False False False\n",
      " False False False False False  True False False False  True False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False  True False False False  True False False False False False\n",
      " False False False False False  True False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False], shape=(100,), dtype=bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:03:10.430644: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in train.take(1):\n",
    "    print(x)\n",
    "    tokens = tokenizer(x[0][0])\n",
    "    print(tokens)\n",
    "    space_tokens = tf.where(tokens == 2, tokens, 3) # Just happen to know e tokenizes to 2 - messy af\n",
    "    print(tf.cast(tf.where(x[1] == 2, x[1], 7), dtype=space_tokens.dtype) == space_tokens) # TODO: investigate what is going on here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 512\n",
    "\n",
    "model = SpaceSegmentationTransformer(\n",
    "    num_layers=2,\n",
    "    d_model=D_MODEL,\n",
    "    num_attention_heads=3,\n",
    "    seq_len=100,\n",
    "    dff=1028,\n",
    "    input_tokenizer=tokenizer,\n",
    "    dropout_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.metrics import SparseAccuracyWithIgnore\n",
    "from segmentation.metrics import SparsePrecision\n",
    "from segmentation.metrics import SparseRecall\n",
    "from segmentation.metrics import SparseF1\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=200):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return 2* tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        SparseAccuracyWithIgnore(ignore_token=0.),\n",
    "        SparsePrecision(class_id=2, name=\"space_precision\"),\n",
    "        SparseRecall(class_id=2, name=\"space_recall\"),\n",
    "        SparseF1(class_id=2, name=\"space_f1\"),\n",
    "        SparsePrecision(class_id=1, name=\"char_precision\"),\n",
    "        SparseRecall(class_id=1, name=\"char_recall\"),\n",
    "        SparseF1(class_id=1, name=\"char_f1\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   7/1000 [..............................] - ETA: 21s - loss: 1.0112 - sparse_categorical_accuracy: 0.6108 - space_precision: 0.1042 - space_recall: 0.0342 - space_f1: 0.0515 - char_precision: 0.9142 - char_recall: 0.6781 - char_f1: 0.7787   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:03:15.582079: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 35ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972 - space_precision: 0.9979 - space_recall: 0.9930 - space_f1: 0.9955 - char_precision: 0.9981 - char_recall: 0.9977 - char_f1: 0.9979 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 1.7881e-12 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9986 - char_recall: 1.0000 - char_f1: 0.9993 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9995 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9988 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9990 - char_recall: 1.0000 - char_f1: 0.9995 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9988 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9995 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9987 - char_recall: 1.0000 - char_f1: 0.9993 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9987 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9989 - char_recall: 1.0000 - char_f1: 0.9995 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9988 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n",
      "Epoch 16/30\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9988 - char_recall: 1.0000 - char_f1: 0.9994 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 0.9986 - val_char_recall: 1.0000 - val_char_f1: 0.9993\n"
     ]
    }
   ],
   "source": [
    "train_ds = train.shuffle(100).batch(8)\n",
    "val_ds = val.batch(8)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_space_precision\",\n",
    "        patience=30,\n",
    "        mode=\"max\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks, steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 13s 13ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 0.9986 - char_recall: 1.0000 - char_f1: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 1.0, 1.0, 0.9986254572868347, 1.0, 0.9993122220039368]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'sparse_categorical_accuracy', 'space_precision', 'space_recall', 'space_f1', 'char_precision', 'char_recall', 'char_f1', 'val_loss', 'val_sparse_categorical_accuracy', 'val_space_precision', 'val_space_recall', 'val_space_f1', 'val_char_precision', 'val_char_recall', 'val_char_f1'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc38f36c100>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvNklEQVR4nO3de1DU973/8ddyWRYRMChBQdTE45HcCg0qxeS0v0wZSeJJo7GnxrHRY+rvN/4GkxA6JtJ4yYmxNO2J9Xpy6Tk9PcWTE5uJMbcpllJj6/yIGNHWTKLRmvGCgmAMC6vcdr+/P8yubkVkYb/73V2fj5mdKV8/u/v+Qrr7ms/VZhiGIQAAgAgXY3UBAAAAwUCoAQAAUYFQAwAAogKhBgAARAVCDQAAiAqEGgAAEBUINQAAICoQagAAQFSIs7qAUPF4PDp16pSSk5Nls9msLgcAAPSDYRhqa2tTZmamYmL67ou5bkLNqVOnlJ2dbXUZAABgAE6cOKHRo0f32ea6CTXJycmSLv5SUlJSLK4GAAD0h9PpVHZ2tu97vC/XTajxDjmlpKQQagAAiDD9mTrCRGEAABAVCDUAACAqEGoAAEBUINQAAICoQKgBAABRgVADAACiAqEGAABEBUINAACICoQaAAAQFQIONX/84x/1wAMPKDMzUzabTdu2bbvmcz744APdeeedSkhI0N/93d/pV7/61RVtNm3apHHjxsnhcKigoEB1dXV+/97R0aGSkhINHz5cQ4cO1axZs9TU1BRo+QAAIEoFHGpcLpdyc3O1adOmfrX//PPPNX36dN1zzz3av3+/SktLtXDhQm3fvt3XZsuWLSorK9PKlStVX1+v3NxcFRcX68yZM742Tz75pN5991298cYb2rlzp06dOqWHHnoo0PIBAECUshmGYQz4yTab3nrrLc2YMeOqbZ5++mm9//77+vjjj33XHn74YX355ZeqqqqSJBUUFGjy5MnauHGjJMnj8Sg7O1uPPfaYli5dqtbWVqWnp+u1117Td7/7XUnSwYMHdcstt6i2tlbf+MY3rlmr0+lUamqqWltbOfsJAIAIEcj3t+kHWtbW1qqoqMjvWnFxsUpLSyVJXV1d2rt3r8rLy33/HhMTo6KiItXW1kqS9u7dq+7ubr/XycnJ0ZgxY64aajo7O9XZ2en72el0BvO2wsIHh85o52fNVpcBAIAkKS7Gpmem32rd+5v9Bo2NjcrIyPC7lpGRIafTqQsXLujcuXNyu929tjl48KDvNex2u4YNG3ZFm8bGxl7ft6KiQv/yL/8SvBsJM4Zh6LHX9qmts8fqUgAAkCTZ42KiO9RYpby8XGVlZb6fnU6nsrOzLawouJwdPb5A83//13jFXPtEdgAATBUbY+2iatNDzciRI69YpdTU1KSUlBQlJiYqNjZWsbGxvbYZOXKk7zW6urr05Zdf+vXWXN7mbyUkJCghISG4NxNGWtovDq0lJ8Tp6XtzLK4GAADrmR6pCgsLVVNT43eturpahYWFkiS73a78/Hy/Nh6PRzU1Nb42+fn5io+P92tz6NAhHT9+3NfmetPSdjHUDB9qt7gSAADCQ8A9Ne3t7Tpy5Ijv588//1z79+9XWlqaxowZo/LycjU0NOjXv/61JGnRokXauHGjnnrqKT366KP6wx/+oN/85jd6//33fa9RVlam+fPna9KkSZoyZYrWrl0rl8ulBQsWSJJSU1P1gx/8QGVlZUpLS1NKSooee+wxFRYW9mvlUzRqae+SJI0YGr29UQAABCLgUPPRRx/pnnvu8f3snbcyf/58/epXv9Lp06d1/Phx37/fdNNNev/99/Xkk09q3bp1Gj16tP793/9dxcXFvjazZ89Wc3OzVqxYocbGRuXl5amqqspv8vDPf/5zxcTEaNasWers7FRxcbH+7d/+bUA3HQ28w0+EGgAALhrUPjWRJNr2qXnxd4e04Q9H9P1vjNHzM+6wuhwAAEwRyPc3Zz9FKHpqAADwR6iJUM1tzKkBAOByhJoIRU8NAAD+CDURyhtq0pNZ0g0AgESoiVhnWdINAIAfQk0EcnX26EK3WxKhBgAAL0JNBPIOPTniYzTEHmtxNQAAhAdCTQS6fJKwzcZJlgAASISaiMRybgAArkSoiUAs5wYA4EqEmgjEcm4AAK5EqIlA9NQAAHAlQk0EamFODQAAVyDURCB6agAAuBKhJgJdCjXMqQEAwItQE4F8RyQk01MDAIAXoSbCdHS71dbZI4nhJwAALkeoiTDeoSd7bIxSHHEWVwMAQPgg1ESYlq+GnoYPtXNEAgAAlyHURJiWNlY+AQDQG0JNhGHlEwAAvSPURBj2qAEAoHeEmgjTwnJuAAB6RaiJMM301AAA0CtCTYS5NFGYOTUAAFyOUBNhzrouDj+l01MDAIAfQk2E8U0UZk4NAAB+CDURpNvt0ZfnuyVJw5MYfgIA4HKEmgjiPcgyNsamG4YQagAAuByhJoJ4h57SkuyKieGIBAAALkeoiSAs5wYA4OoINRGE5dwAAFwdoSaCeHcTZjk3AABXItREEJZzAwBwdYSaCMIJ3QAAXB2hJoJ4l3QzURgAgCsRaiJIC6ufAAC4KkJNBPGGmuEMPwEAcAVCTYRwewx9wWGWAABcFaEmQnzh6pLHkGy2izsKAwAAf4SaCOEderphiF1xsfzZAAD4W3w7RgiWcwMA0DdCTYRg5RMAAH0j1ESIljb2qAEAoC+EmghBTw0AAH0j1EQI72GWI5KZUwMAQG8INRGCnhoAAPpGqIkQ3lDDxnsAAPSOUBMhOCIBAIC+EWoigMdjcEI3AADXQKiJAK0XutXjMSTRUwMAwNUQaiKAd+gpxRGnhLhYi6sBACA8EWoiQLN35VMyQ08AAFwNoSYCtDCfBgCAayLURICWNpZzAwBwLYSaCMAJ3QAAXBuhJgKwnBsAgGsj1ESAFiYKAwBwTYSaCODbTTiJ4ScAAK6GUBMBLp3QTU8NAABXQ6gJc4Zh+PapYfUTAABXR6gJc22dPerq8UhiojAAAH0h1IQ57x41SfZYJdo5IgEAgKsZUKjZtGmTxo0bJ4fDoYKCAtXV1V21bXd3t5577jmNHz9eDodDubm5qqqq8mvT1tam0tJSjR07VomJiZo6dar27Nnj16apqUn//M//rMzMTA0ZMkT33nuvDh8+PJDyIwrzaQAA6J+AQ82WLVtUVlamlStXqr6+Xrm5uSouLtaZM2d6bb9s2TK98sor2rBhgz755BMtWrRIM2fO1L59+3xtFi5cqOrqalVWVurAgQOaNm2aioqK1NDQIOnivJIZM2bo6NGjevvtt7Vv3z6NHTtWRUVFcrlcA7z1yHBp4z1CDQAAfTICNGXKFKOkpMT3s9vtNjIzM42Kiope248aNcrYuHGj37WHHnrImDt3rmEYhnH+/HkjNjbWeO+99/za3HnnncYzzzxjGIZhHDp0yJBkfPzxx37vm56ebvziF7/oV92tra2GJKO1tbVf7cPFf/2/z42xT79n/J9f77G6FAAAQi6Q7++Aemq6urq0d+9eFRUV+a7FxMSoqKhItbW1vT6ns7NTDofD71piYqJ27dolSerp6ZHb7e6zTWfnxd6Ky9vExMQoISHB1yZacZglAAD9E1CoaWlpkdvtVkZGht/1jIwMNTY29vqc4uJirVmzRocPH5bH41F1dbW2bt2q06dPS5KSk5NVWFioVatW6dSpU3K73dq8ebNqa2t9bXJycjRmzBiVl5fr3Llz6urq0gsvvKCTJ0/62vytzs5OOZ1Ov0ckYvgJAID+MX3107p16zRhwgTl5OTIbrdr8eLFWrBggWJiLr11ZWWlDMNQVlaWEhIStH79es2ZM8fXJj4+Xlu3btVnn32mtLQ0DRkyRDt27NB9993n9zqXq6ioUGpqqu+RnZ1t9q2awrv6iYnCAAD0LaBQM2LECMXGxqqpqcnvelNTk0aOHNnrc9LT07Vt2za5XC4dO3ZMBw8e1NChQ3XzzTf72owfP147d+5Ue3u7Tpw4obq6OnV3d/u1yc/P1/79+/Xll1/q9OnTqqqq0tmzZ/3aXK68vFytra2+x4kTJwK51bDh66nhiAQAAPoUUKix2+3Kz89XTU2N75rH41FNTY0KCwv7fK7D4VBWVpZ6enr05ptv6sEHH7yiTVJSkkaNGqVz585p+/btvbZJTU1Venq6Dh8+rI8++qjXNpKUkJCglJQUv0ckYkk3AAD9ExfoE8rKyjR//nxNmjRJU6ZM0dq1a+VyubRgwQJJ0rx585SVlaWKigpJ0u7du9XQ0KC8vDw1NDTo2Weflcfj0VNPPeV7ze3bt8swDE2cOFFHjhzRkiVLlJOT43tNSXrjjTeUnp6uMWPG6MCBA3riiSc0Y8YMTZs2bbC/g7DGnBoAAPon4FAze/ZsNTc3a8WKFWpsbFReXp6qqqp8k4ePHz/uN8+lo6NDy5Yt09GjRzV06FDdf//9qqys1LBhw3xtWltbVV5erpMnTyotLU2zZs3S6tWrFR8f72tz+vRplZWVqampSaNGjdK8efO0fPnyQdx6+Dvf1aPzXW5J0oihDD8BANAXm2EYhtVFhILT6VRqaqpaW1sjZijq+Nnz+ubPdighLkYHV90rm81mdUkAAIRUIN/fnP0UxpovG3oi0AAA0DdCTRjzzadhkjAAANdEqAljZ79a+ZTOfBoAAK6JUBPGWPkEAED/EWrCGKEGAID+I9SEMW+oGc7wEwAA10SoCWMtbZzQDQBAfxFqwhjDTwAA9B+hJox596lJT2b4CQCAayHUhKmObrfaOnok0VMDAEB/EGrC1FnXxfk08bE2pSbGX6M1AAAg1ISplravVj4lcUQCAAD9QagJU2dd3iMSmE8DAEB/EGrCFMu5AQAIDKEmTDWznBsAgIAQasIUe9QAABAYQk2Yamn3Dj8xpwYAgP4g1IQp7+onemoAAOgfQk2YYvgJAIDAEGrClC/UsKQbAIB+IdSEoW63R+fOd0uipwYAgP4i1IShL746IiHGJt0whJ4aAAD6g1AThpq/miSclpSg2BiOSAAAoD8INWHIe5gly7kBAOg/Qk0Y8i7nTk9mPg0AAP1FqAlDLOcGACBwhJow5A01w5MYfgIAoL8INWHId0QCw08AAPQboSYMMfwEAEDgCDVhqNl37hPDTwAA9BehJgxdOqGbnhoAAPqLUBNm3B5DX7hY0g0AQKAINWHm3PkueYyL/zuN1U8AAPQboSbMnP1q6OmGIfGKj+XPAwBAf/GtGWZY+QQAwMAQasIMoQYAgIEh1IQZ33JuJgkDABAQQk2Y8S7n5ogEAAACQ6gJM97hJ5ZzAwAQGEJNmLk0p4aeGgAAAkGoCTNMFAYAYGAINWGmpY0jEgAAGAhCTRgxDENnXax+AgBgIAg1YcR5oUfd7otnJLD6CQCAwBBqwkjzV/Npkh1xcsTHWlwNAACRhVATRnzLuZlPAwBAwAg1YYSVTwAADByhJoy0fHVEwnD2qAEAIGCEmjDiPSKBnhoAAAJHqAkjDD8BADBwhJow4gs1yQw/AQAQKEJNGGlm+AkAgAEj1IQR70RhQg0AAIEj1IQJwzDYpwYAgEEg1IQJV5dbnT0eScypAQBgIAg1YcI79DTEHqsh9jiLqwEAIPIQasIEy7kBABgcQk2YuBRqGHoCAGAgCDVhwrucezg9NQAADAihJkywnBsAgMEh1ISJS8u5GX4CAGAgCDVh4tIRCfTUAAAwEISaMMEJ3QAADA6hJkywpBsAgMEZUKjZtGmTxo0bJ4fDoYKCAtXV1V21bXd3t5577jmNHz9eDodDubm5qqqq8mvT1tam0tJSjR07VomJiZo6dar27Nnj16a9vV2LFy/W6NGjlZiYqFtvvVUvv/zyQMoPS2d9PTXMqQEAYCACDjVbtmxRWVmZVq5cqfr6euXm5qq4uFhnzpzptf2yZcv0yiuvaMOGDfrkk0+0aNEizZw5U/v27fO1Wbhwoaqrq1VZWakDBw5o2rRpKioqUkNDg69NWVmZqqqqtHnzZn366acqLS3V4sWL9c477wzgtsNLR7db7Z09kphTAwDAQNkMwzACeUJBQYEmT56sjRs3SpI8Ho+ys7P12GOPaenSpVe0z8zM1DPPPKOSkhLftVmzZikxMVGbN2/WhQsXlJycrLffflvTp0/3tcnPz9d9992n559/XpJ0++23a/bs2Vq+fPlV2/TF6XQqNTVVra2tSklJCeSWTXfii/P6h5/ukD0uRodW3SubzWZ1SQAAhIVAvr8D6qnp6urS3r17VVRUdOkFYmJUVFSk2traXp/T2dkph8Phdy0xMVG7du2SJPX09MjtdvfZRpKmTp2qd955Rw0NDTIMQzt27NBnn32madOmXfV9nU6n3yNcXX46N4EGAICBCSjUtLS0yO12KyMjw+96RkaGGhsbe31OcXGx1qxZo8OHD8vj8ai6ulpbt27V6dOnJUnJyckqLCzUqlWrdOrUKbndbm3evFm1tbW+NpK0YcMG3XrrrRo9erTsdrvuvfdebdq0Sd/85jd7fd+Kigqlpqb6HtnZ2YHcaki1+HYTZj4NAAADZfrqp3Xr1mnChAnKycmR3W7X4sWLtWDBAsXEXHrryspKGYahrKwsJSQkaP369ZozZ45fmw0bNujDDz/UO++8o7179+rFF19USUmJfv/73/f6vuXl5WptbfU9Tpw4YfatDhgrnwAAGLy4QBqPGDFCsbGxampq8rve1NSkkSNH9vqc9PR0bdu2TR0dHTp79qwyMzO1dOlS3Xzzzb4248eP186dO+VyueR0OjVq1CjNnj3b1+bChQv60Y9+pLfeess37+ZrX/ua9u/fr3/913/1Gw7zSkhIUEJCZISES0ck0FMDAMBABdRTY7fblZ+fr5qaGt81j8ejmpoaFRYW9vlch8OhrKws9fT06M0339SDDz54RZukpCSNGjVK586d0/bt231turu71d3d7ddzI0mxsbHyeDyB3EJYoqcGAIDBC6inRrq4tHr+/PmaNGmSpkyZorVr18rlcmnBggWSpHnz5ikrK0sVFRWSpN27d6uhoUF5eXlqaGjQs88+K4/Ho6eeesr3mtu3b5dhGJo4caKOHDmiJUuWKCcnx/eaKSkp+ta3vqUlS5YoMTFRY8eO1c6dO/XrX/9aa9asCcbvwVLsJgwAwOAFHGpmz56t5uZmrVixQo2NjcrLy1NVVZVv8vDx48f9elQ6Ojq0bNkyHT16VEOHDtX999+vyspKDRs2zNemtbVV5eXlOnnypNLS0jRr1iytXr1a8fHxvjavv/66ysvLNXfuXH3xxRcaO3asVq9erUWLFg3i9sNDM+c+AQAwaAHvUxOpwnmfmm+/+IH+2uzSa/+7QFPHj7C6HAAAwoZp+9TAHN7hp3SGnwAAGDBCjcW6ejxqvdAtiTk1AAAMBqHGYmddF+fTxMXYlJoYf43WAADgagg1Fmtpu7SbcEwMRyQAADBQhBqLefeoGZ7E0BMAAINBqLEYy7kBAAgOQo3FLu0mzBEJAAAMBqHGYt45NSznBgBgcAg1FuPcJwAAgoNQYzHvku4RyQw/AQAwGIQai3mHn+ipAQBgcAg1FmP4CQCA4CDUWKjH7dEX5+mpAQAgGAg1FvrifJcMQ7LZpLQk5tQAADAYhBoLeefTpA2xK5YjEgAAGBRCjYWYTwMAQPAQaizkCzUs5wYAYNAINRaipwYAgOAh1FiopZ2VTwAABAuhxkItbfTUAAAQLIQaC7W4vD01zKkBAGCwCDUW8vXUJNNTAwDAYBFqLOSdKJzO8BMAAINGqLGIx2PorIuJwgAABAuhxiJfXuiW22NI4ogEAACCgVBjEe/QU2pivOxx/BkAABgsvk0tcmk5N700AAAEA6HGIs3sJgwAQFARaizi202Y5dwAAAQFocYiLOcGACC4CDUWOdvOnBoAAIKJUGMRDrMEACC4CDUWaWGiMAAAQUWosQjnPgEAEFyEGgsYhnHZ8BNzagAACAZCjQWcHT3qcnskMfwEAECwEGos4J1PMzQhTo74WIurAQAgOhBqLMARCQAABB+hxgIs5wYAIPgINRZgOTcAAMFHqLGAbzfhZIafAAAIFkKNBZoZfgIAIOgINRZg+AkAgOAj1FiAUAMAQPARaizgDTXpzKkBACBoCDUWaGljTg0AAMFGqAkxV2ePLnS7JUnDCTUAAAQNoSbEvENPjvgYJdk5IgEAgGAh1ITY5ZOEbTabxdUAABA9CDUh1sx8GgAATEGoCbGzLpZzAwBgBkJNiHlXPrGcGwCA4CLUhBgb7wEAYA5CTYgRagAAMAehJsQINQAAmINQE2ItvhO6mVMDAEAwEWpCrKXtYk8NuwkDABBchJoQ6uh2q62zR5KUTqgBACCoCDUh5J1PY4+NUUpinMXVAAAQXQg1IeSdTzN8qJ0jEgAACDJCTQh559Ow8gkAgOAj1ITQpSMSWPkEAECwEWpC6NJybnpqAAAItgGFmk2bNmncuHFyOBwqKChQXV3dVdt2d3frueee0/jx4+VwOJSbm6uqqiq/Nm1tbSotLdXYsWOVmJioqVOnas+ePX5tbDZbr4+f/exnA7kFSzR7h5+SCTUAAARbwKFmy5YtKisr08qVK1VfX6/c3FwVFxfrzJkzvbZftmyZXnnlFW3YsEGffPKJFi1apJkzZ2rfvn2+NgsXLlR1dbUqKyt14MABTZs2TUVFRWpoaPC1OX36tN/jl7/8pWw2m2bNmjWA27YGuwkDAGAem2EYRiBPKCgo0OTJk7Vx40ZJksfjUXZ2th577DEtXbr0ivaZmZl65plnVFJS4rs2a9YsJSYmavPmzbpw4YKSk5P19ttva/r06b42+fn5uu+++/T888/3WseMGTPU1tammpqaftXtdDqVmpqq1tZWpaSkBHLLQfPwq7X68OgXWvdwnh7My7KkBgAAIkkg398B9dR0dXVp7969KioquvQCMTEqKipSbW1tr8/p7OyUw+Hwu5aYmKhdu3ZJknp6euR2u/ts87eampr0/vvv6wc/+MFVa+3s7JTT6fR7WM07p4aN9wAACL6AQk1LS4vcbrcyMjL8rmdkZKixsbHX5xQXF2vNmjU6fPiwPB6PqqurtXXrVp0+fVqSlJycrMLCQq1atUqnTp2S2+3W5s2bVVtb62vzt/7rv/5LycnJeuihh65aa0VFhVJTU32P7OzsQG7VFN7hJ45IAAAg+Exf/bRu3TpNmDBBOTk5stvtWrx4sRYsWKCYmEtvXVlZKcMwlJWVpYSEBK1fv15z5szxa3O5X/7yl5o7d+4VvTuXKy8vV2trq+9x4sSJoN9bILrdHn15vlsSS7oBADBDQKFmxIgRio2NVVNTk9/1pqYmjRw5stfnpKena9u2bXK5XDp27JgOHjyooUOH6uabb/a1GT9+vHbu3Kn29nadOHFCdXV16u7u9mvj9ac//UmHDh3SwoUL+6w1ISFBKSkpfg8rnf1q6Ck2xqYbhhBqAAAItoBCjd1uV35+vt/kXI/Ho5qaGhUWFvb5XIfDoaysLPX09OjNN9/Ugw8+eEWbpKQkjRo1SufOndP27dt7bfMf//Efys/PV25ubiClW8479JSWZFdMDEckAAAQbAGfqlhWVqb58+dr0qRJmjJlitauXSuXy6UFCxZIkubNm6esrCxVVFRIknbv3q2Ghgbl5eWpoaFBzz77rDwej5566infa27fvl2GYWjixIk6cuSIlixZopycHN9rejmdTr3xxht68cUXB3PPlmA5NwAA5go41MyePVvNzc1asWKFGhsblZeXp6qqKt/k4ePHj/vNheno6NCyZct09OhRDR06VPfff78qKys1bNgwX5vW1laVl5fr5MmTSktL06xZs7R69WrFx8f7vffrr78uwzA0Z86cAd6udS7tJszQEwAAZgh4n5pIZfU+NS/v/Kt+8tuDeujrWVozOy/k7w8AQCQybZ8aDFwLRyQAAGAqQk2IXJpTw/ATAABmINSECCd0AwBgLkJNiLCbMAAA5iLUhAjDTwAAmItQEwJuj6EvXBxmCQCAmQg1IfCFq0seQ7LZLu4oDAAAgo9QEwJnXReHnm4YYldcLL9yAADMwDdsCLS0sZswAABmI9SEAOc+AQBgPkJNCBBqAAAwH6EmBJoJNQAAmI5QEwK+OTXJzKkBAMAshJoQYPgJAADzEWpCgN2EAQAwH6EmBOipAQDAfIQak3k8hs5yQjcAAKYj1Jis9UK3ejyGJGk4w08AAJiGUGMy7xEJKY44JcTFWlwNAADRi1Bjsmbfcm6GngAAMBOhxmRMEgYAIDQINSbzhpp0Qg0AAKYi1JiMPWoAAAgNQo3JfEck0FMDAICpCDUm8/bUDCfUAABgKkKNyRh+AgAgNAg1JmtpZ0k3AAChQKgxkWEYamb1EwAAIUGoMVF7Z4+6ejySmCgMAIDZCDUm8g49JdljlWjniAQAAMxEqDGRb5Iw82kAADAdocZELW0ckQAAQKgQakzEcm4AAEKHUGOi5nZ2EwYAIFQINSbihG4AAEKHUGOiS3NqGH4CAMBshBoT0VMDAEDoEGpMxBEJAACEDqHGRGfpqQEAIGQINSa50OWWq8stiTk1AACEAqHGJN75NAlxMRqaEGdxNQAARD9CjUmaLxt6stlsFlcDAED0I9SYxLecm0nCAACEBKHGJN6VT+nMpwEAICQINSZhjxoAAEKLUGMSb6gZTk8NAAAhQagxCT01AACEFqHGJC1tnNANAEAoEWpM0uKipwYAgFAi1JjEu6Q7PZk5NQAAhAKhxgSdPW45O3ok0VMDAECoEGpMcParPWriY21KTYy3uBoAAK4PhBoT+JZzJ3FEAgAAoUKoMYFvOTfzaQAACBlCjQlYzg0AQOgRakzQzMZ7AACEHKHGBByRAABA6BFqTHDphG56agAACBVCjQm8G+8x/AQAQOgQakxwliMSAAAIOUKNCbzDTyzpBgAgdAg1Qdbj9ujceZZ0AwAQaoSaIPvC1SXDkGJs0g1D6KkBACBUBhRqNm3apHHjxsnhcKigoEB1dXVXbdvd3a3nnntO48ePl8PhUG5urqqqqvzatLW1qbS0VGPHjlViYqKmTp2qPXv2XPFan376qb7zne8oNTVVSUlJmjx5so4fPz6QWzCNd4+atKQExcZwRAIAAKEScKjZsmWLysrKtHLlStXX1ys3N1fFxcU6c+ZMr+2XLVumV155RRs2bNAnn3yiRYsWaebMmdq3b5+vzcKFC1VdXa3KykodOHBA06ZNU1FRkRoaGnxt/vrXv+ruu+9WTk6OPvjgA/3lL3/R8uXL5XA4BnDb5vHNp2GPGgAAQspmGIYRyBMKCgo0efJkbdy4UZLk8XiUnZ2txx57TEuXLr2ifWZmpp555hmVlJT4rs2aNUuJiYnavHmzLly4oOTkZL399tuaPn26r01+fr7uu+8+Pf/885Kkhx9+WPHx8aqsrBzQjTqdTqWmpqq1tVUpKSkDeo3+eHPvSf3wjT/rHyaMUOUPCkx7HwAArgeBfH8H1FPT1dWlvXv3qqio6NILxMSoqKhItbW1vT6ns7Pzit6UxMRE7dq1S5LU09Mjt9vdZxuPx6P3339ff//3f6/i4mLdeOONKigo0LZt265aa2dnp5xOp98jFC6d0E1PDQAAoRRQqGlpaZHb7VZGRobf9YyMDDU2Nvb6nOLiYq1Zs0aHDx+Wx+NRdXW1tm7dqtOnT0uSkpOTVVhYqFWrVunUqVNyu93avHmzamtrfW3OnDmj9vZ2/eQnP9G9996r3/3ud5o5c6Yeeugh7dy5s9f3raioUGpqqu+RnZ0dyK0OWAvnPgEAYAnTVz+tW7dOEyZMUE5Ojux2uxYvXqwFCxYoJubSW1dWVsowDGVlZSkhIUHr16/XnDlzfG08Ho8k6cEHH9STTz6pvLw8LV26VP/4j/+ol19+udf3LS8vV2trq+9x4sQJs29V0uV71BBqAAAIpYBCzYgRIxQbG6umpia/601NTRo5cmSvz0lPT9e2bdvkcrl07NgxHTx4UEOHDtXNN9/sazN+/Hjt3LlT7e3tOnHihOrq6tTd3e1rM2LECMXFxenWW2/1e+1bbrnlqqufEhISlJKS4vcIBXpqAACwRkChxm63Kz8/XzU1Nb5rHo9HNTU1Kiws7PO5DodDWVlZ6unp0ZtvvqkHH3zwijZJSUkaNWqUzp07p+3bt/va2O12TZ48WYcOHfJr/9lnn2ns2LGB3ILpWP0EAIA14gJ9QllZmebPn69JkyZpypQpWrt2rVwulxYsWCBJmjdvnrKyslRRUSFJ2r17txoaGpSXl6eGhgY9++yz8ng8euqpp3yvuX37dhmGoYkTJ+rIkSNasmSJcnJyfK8pSUuWLNHs2bP1zW9+U/fcc4+qqqr07rvv6oMPPhjkryC46KkBAMAaAYea2bNnq7m5WStWrFBjY6Py8vJUVVXlmzx8/Phxv/kyHR0dWrZsmY4ePaqhQ4fq/vvvV2VlpYYNG+Zr09raqvLycp08eVJpaWmaNWuWVq9erfj4eF+bmTNn6uWXX1ZFRYUef/xxTZw4UW+++abuvvvuQdx+cHk8hr5wXeypSWdODQAAIRXwPjWRKhT71Jxt71T+87+XJB1efZ/iYzmFAgCAwTBtnxr0zTuf5oYh8QQaAABCjG/eIGI+DQAA1iHUBBGhBgAA6xBqgqi57asjEljODQBAyBFqgujSHjX01AAAEGqEmiA6+9XwE8u5AQAIPUJNEF2aU8PwEwAAoUaoCSKGnwAAsA6hJohY/QQAgHUINUFiGIbOentqmFMDAEDIEWqCxHmhR11ujyRpeBJzagAACDVCTZA0fzX0lOyIkyM+1uJqAAC4/hBqgsQ7nyad+TQAAFiCUBMk3lDDbsIAAFiDUBMkLW2sfAIAwEqEmiA562KPGgAArESoCRL2qAEAwFqEmiBpbvPuUcOcGgAArECoCRJ6agAAsBahJkgINQAAWItQEwSGYbBPDQAAFiPUBIGry62O7otHJDCnBgAAaxBqgsC7R80Qe6yG2OMsrgYAgOsToSYI2E0YAADrEWqCgEnCAABYj1ATBM3t7CYMAIDVCDVBcJaeGgAALEeoCYJLy7mZUwMAgFUINUHQ4jsigZ4aAACsQqgJAiYKAwBgPUJNEBBqAACwHqEmCFp8q5+YUwMAgFUINYPU0e1We2ePJObUAABgJfb0HySPYWhJ8USdbe9ScgK/TgAArMK38CANscep5J6/s7oMAACueww/AQCAqECoAQAAUYFQAwAAogKhBgAARAVCDQAAiAqEGgAAEBUINQAAICoQagAAQFQg1AAAgKhAqAEAAFGBUAMAAKICoQYAAEQFQg0AAIgK180p3YZhSJKcTqfFlQAAgP7yfm97v8f7ct2Emra2NklSdna2xZUAAIBAtbW1KTU1tc82NqM/0ScKeDwenTp1SsnJybLZbEF9bafTqezsbJ04cUIpKSlBfe1wxP1Gt+vtfqXr75653+gWbfdrGIba2tqUmZmpmJi+Z81cNz01MTExGj16tKnvkZKSEhX/AfUX9xvdrrf7la6/e+Z+o1s03e+1emi8mCgMAACiAqEGAABEBUJNECQkJGjlypVKSEiwupSQ4H6j2/V2v9L1d8/cb3S73u73ctfNRGEAABDd6KkBAABRgVADAACiAqEGAABEBUINAACICoSaINi0aZPGjRsnh8OhgoIC1dXVWV2SKSoqKjR58mQlJyfrxhtv1IwZM3To0CGrywqZn/zkJ7LZbCotLbW6FNM0NDTo+9//voYPH67ExETdcccd+uijj6wuyxRut1vLly/XTTfdpMTERI0fP16rVq3q1/kykeCPf/yjHnjgAWVmZspms2nbtm1+/24YhlasWKFRo0YpMTFRRUVFOnz4sDXFBkFf99vd3a2nn35ad9xxh5KSkpSZmal58+bp1KlT1hUcBNf6G19u0aJFstlsWrt2bcjqswKhZpC2bNmisrIyrVy5UvX19crNzVVxcbHOnDljdWlBt3PnTpWUlOjDDz9UdXW1uru7NW3aNLlcLqtLM92ePXv0yiuv6Gtf+5rVpZjm3LlzuuuuuxQfH6/f/va3+uSTT/Tiiy/qhhtusLo0U7zwwgt66aWXtHHjRn366ad64YUX9NOf/lQbNmywurSgcLlcys3N1aZNm3r995/+9Kdav369Xn75Ze3evVtJSUkqLi5WR0dHiCsNjr7u9/z586qvr9fy5ctVX1+vrVu36tChQ/rOd75jQaXBc62/sddbb72lDz/8UJmZmSGqzEIGBmXKlClGSUmJ72e3221kZmYaFRUVFlYVGmfOnDEkGTt37rS6FFO1tbUZEyZMMKqrq41vfetbxhNPPGF1SaZ4+umnjbvvvtvqMkJm+vTpxqOPPup37aGHHjLmzp1rUUXmkWS89dZbvp89Ho8xcuRI42c/+5nv2pdffmkkJCQY//M//2NBhcH1t/fbm7q6OkOScezYsdAUZbKr3fPJkyeNrKws4+OPPzbGjh1r/PznPw95baFET80gdHV1ae/evSoqKvJdi4mJUVFRkWpray2sLDRaW1slSWlpaRZXYq6SkhJNnz7d7+8cjd555x1NmjRJ//RP/6Qbb7xRX//61/WLX/zC6rJMM3XqVNXU1Oizzz6TJP35z3/Wrl27dN9991lcmfk+//xzNTY2+v03nZqaqoKCguvis0u6+Plls9k0bNgwq0sxjcfj0SOPPKIlS5botttus7qckLhuDrQ0Q0tLi9xutzIyMvyuZ2Rk6ODBgxZVFRoej0elpaW66667dPvtt1tdjmlef/111dfXa8+ePVaXYrqjR4/qpZdeUllZmX70ox9pz549evzxx2W32zV//nyrywu6pUuXyul0KicnR7GxsXK73Vq9erXmzp1rdWmma2xslKReP7u8/xbNOjo69PTTT2vOnDlRc+Bjb1544QXFxcXp8ccft7qUkCHUYEBKSkr08ccfa9euXVaXYpoTJ07oiSeeUHV1tRwOh9XlmM7j8WjSpEn68Y9/LEn6+te/ro8//lgvv/xyVIaa3/zmN/rv//5vvfbaa7rtttu0f/9+lZaWKjMzMyrvFxd1d3fre9/7ngzD0EsvvWR1OabZu3ev1q1bp/r6etlsNqvLCRmGnwZhxIgRio2NVVNTk9/1pqYmjRw50qKqzLd48WK999572rFjh0aPHm11OabZu3evzpw5ozvvvFNxcXGKi4vTzp07tX79esXFxcntdltdYlCNGjVKt956q9+1W265RcePH7eoInMtWbJES5cu1cMPP6w77rhDjzzyiJ588klVVFRYXZrpvJ9P19tnlzfQHDt2TNXV1VHdS/OnP/1JZ86c0ZgxY3yfX8eOHdMPf/hDjRs3zuryTEOoGQS73a78/HzV1NT4rnk8HtXU1KiwsNDCysxhGIYWL16st956S3/4wx900003WV2Sqb797W/rwIED2r9/v+8xadIkzZ07V/v371dsbKzVJQbVXXfddcUS/c8++0xjx461qCJznT9/XjEx/h+BsbGx8ng8FlUUOjfddJNGjhzp99nldDq1e/fuqPzski4FmsOHD+v3v/+9hg8fbnVJpnrkkUf0l7/8xe/zKzMzU0uWLNH27dutLs80DD8NUllZmebPn69JkyZpypQpWrt2rVwulxYsWGB1aUFXUlKi1157TW+//baSk5N9Y++pqalKTEy0uLrgS05OvmK+UFJSkoYPHx6V84iefPJJTZ06VT/+8Y/1ve99T3V1dXr11Vf16quvWl2aKR544AGtXr1aY8aM0W233aZ9+/ZpzZo1evTRR60uLSja29t15MgR38+ff/659u/fr7S0NI0ZM0alpaV6/vnnNWHCBN10001avny5MjMzNWPGDOuKHoS+7nfUqFH67ne/q/r6er333ntyu92+z6+0tDTZ7Xaryh6Ua/2N/za4xcfHa+TIkZo4cWKoSw0dq5dfRYMNGzYYY8aMMex2uzFlyhTjww8/tLokU0jq9fGf//mfVpcWMtG8pNswDOPdd981br/9diMhIcHIyckxXn31VatLMo3T6TSeeOIJY8yYMYbD4TBuvvlm45lnnjE6OzutLi0oduzY0ev/X+fPn28YxsVl3cuXLzcyMjKMhIQE49vf/rZx6NAha4sehL7u9/PPP7/q59eOHTusLn3ArvU3/lvXw5Jum2FEyfaZAADgusacGgAAEBUINQAAICoQagAAQFQg1AAAgKhAqAEAAFGBUAMAAKICoQYAAEQFQg0AAIgKhBoAABAVCDUAACAqEGoAAEBUINQAAICo8P8B8Cl5ND0y9XoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['space_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 100, 3), dtype=float32, numpy=\n",
       " array([[[-1.72272511e+01,  1.08881941e+01, -1.82745438e+01],\n",
       "         [-1.72941208e+01,  1.02743559e+01, -1.85116863e+01],\n",
       "         [-1.63078632e+01,  1.19491501e+01, -1.83472385e+01],\n",
       "         [-1.61852188e+01,  1.22892437e+01, -1.82589092e+01],\n",
       "         [-1.66375103e+01,  1.14915848e+01, -1.88646717e+01],\n",
       "         [-1.61403446e+01,  1.25418501e+01, -1.79797649e+01],\n",
       "         [-1.69376698e+01,  1.07281914e+01, -1.85887012e+01],\n",
       "         [-1.63964405e+01,  1.19633036e+01, -1.81003876e+01],\n",
       "         [-1.61507835e+01,  1.30331736e+01, -1.85830135e+01],\n",
       "         [-1.70402699e+01,  1.15131435e+01, -1.85363483e+01],\n",
       "         [-1.72560482e+01,  1.10907679e+01, -1.88165359e+01],\n",
       "         [-1.93194408e+01, -1.99273071e+01,  8.69643211e+00],\n",
       "         [-1.63327370e+01,  1.33591204e+01, -1.84804802e+01],\n",
       "         [-1.46408854e+01,  3.36835456e+00, -1.70105381e+01],\n",
       "         [-1.46143618e+01,  3.43356252e+00, -1.70836315e+01],\n",
       "         [-1.46387949e+01,  3.61204815e+00, -1.72450905e+01],\n",
       "         [-1.47097397e+01,  3.72446084e+00, -1.73229809e+01],\n",
       "         [-1.48023319e+01,  3.56146193e+00, -1.72328014e+01],\n",
       "         [-1.48997526e+01,  3.16083527e+00, -1.69664593e+01],\n",
       "         [-1.49993238e+01,  2.65477371e+00, -1.66531353e+01],\n",
       "         [-1.50779495e+01,  2.28237796e+00, -1.64767971e+01],\n",
       "         [-1.51727953e+01,  2.16580677e+00, -1.64314823e+01],\n",
       "         [-1.52488699e+01,  2.40758657e+00, -1.65788021e+01],\n",
       "         [-1.52284250e+01,  2.91576934e+00, -1.68496704e+01],\n",
       "         [-1.51269093e+01,  3.46573567e+00, -1.70934334e+01],\n",
       "         [-1.49385347e+01,  3.89539719e+00, -1.72973347e+01],\n",
       "         [-1.47967386e+01,  4.03580475e+00, -1.74128971e+01],\n",
       "         [-1.48020658e+01,  3.87349772e+00, -1.73948612e+01],\n",
       "         [-1.49592724e+01,  3.50678539e+00, -1.72101173e+01],\n",
       "         [-1.51553469e+01,  3.06979799e+00, -1.69839725e+01],\n",
       "         [-1.52736855e+01,  2.74941659e+00, -1.68132610e+01],\n",
       "         [-1.52804852e+01,  2.64421415e+00, -1.67347317e+01],\n",
       "         [-1.51443701e+01,  2.79962444e+00, -1.68065929e+01],\n",
       "         [-1.50150785e+01,  3.14067125e+00, -1.69792156e+01],\n",
       "         [-1.49498234e+01,  3.48795748e+00, -1.71353779e+01],\n",
       "         [-1.49832478e+01,  3.67833710e+00, -1.71708641e+01],\n",
       "         [-1.50970659e+01,  3.70718575e+00, -1.71037006e+01],\n",
       "         [-1.51367712e+01,  3.62239885e+00, -1.70072517e+01],\n",
       "         [-1.50119209e+01,  3.46526623e+00, -1.69504757e+01],\n",
       "         [-1.48110161e+01,  3.26287031e+00, -1.69404144e+01],\n",
       "         [-1.46219654e+01,  3.11664701e+00, -1.70007858e+01],\n",
       "         [-1.45977716e+01,  3.00650883e+00, -1.70707569e+01],\n",
       "         [-1.47326174e+01,  2.97854757e+00, -1.70663910e+01],\n",
       "         [-1.48894587e+01,  3.07211065e+00, -1.70471001e+01],\n",
       "         [-1.49784822e+01,  3.28196692e+00, -1.70289574e+01],\n",
       "         [-1.49910784e+01,  3.51690102e+00, -1.70029678e+01],\n",
       "         [-1.49055586e+01,  3.76309085e+00, -1.70076275e+01],\n",
       "         [-1.48373203e+01,  3.98820019e+00, -1.70300236e+01],\n",
       "         [-1.48696737e+01,  3.98623538e+00, -1.69978085e+01],\n",
       "         [-1.49972706e+01,  3.76724505e+00, -1.68814697e+01],\n",
       "         [-1.51265955e+01,  3.44826555e+00, -1.67210922e+01],\n",
       "         [-1.52074375e+01,  3.25636578e+00, -1.66305256e+01],\n",
       "         [-1.52564096e+01,  3.25010133e+00, -1.66551228e+01],\n",
       "         [-1.52742825e+01,  3.41790915e+00, -1.67620392e+01],\n",
       "         [-1.52641926e+01,  3.65893197e+00, -1.69020882e+01],\n",
       "         [-1.52049170e+01,  3.85544872e+00, -1.70432377e+01],\n",
       "         [-1.51257162e+01,  3.93865728e+00, -1.70998955e+01],\n",
       "         [-1.50805912e+01,  3.93541074e+00, -1.70394936e+01],\n",
       "         [-1.50483561e+01,  3.87726378e+00, -1.69976959e+01],\n",
       "         [-1.49973488e+01,  3.90556431e+00, -1.71184139e+01],\n",
       "         [-1.49347181e+01,  4.01630020e+00, -1.73928394e+01],\n",
       "         [-1.49015417e+01,  4.19407511e+00, -1.76920643e+01],\n",
       "         [-1.48540421e+01,  4.33295345e+00, -1.78724899e+01],\n",
       "         [-1.47741632e+01,  4.39810371e+00, -1.78214397e+01],\n",
       "         [-1.46630344e+01,  4.40284395e+00, -1.75812550e+01],\n",
       "         [-1.45322523e+01,  4.34198666e+00, -1.72542629e+01],\n",
       "         [-1.44619122e+01,  4.17687798e+00, -1.69694633e+01],\n",
       "         [-1.44118519e+01,  5.16498566e+00, -1.72157040e+01],\n",
       "         [-1.45391445e+01,  4.99253798e+00, -1.72511005e+01],\n",
       "         [-1.47542505e+01,  3.76919603e+00, -1.69290390e+01],\n",
       "         [-1.48690662e+01,  3.69476891e+00, -1.69886971e+01],\n",
       "         [-1.49197588e+01,  3.68918967e+00, -1.70202923e+01],\n",
       "         [-1.48914557e+01,  3.82696366e+00, -1.71038227e+01],\n",
       "         [-1.48306828e+01,  4.03732395e+00, -1.72437191e+01],\n",
       "         [-1.47604828e+01,  4.21152115e+00, -1.73784046e+01],\n",
       "         [-1.46979628e+01,  4.17725229e+00, -1.74727955e+01],\n",
       "         [-1.46299429e+01,  3.89539695e+00, -1.74683933e+01],\n",
       "         [-1.45937319e+01,  3.50739312e+00, -1.73545132e+01],\n",
       "         [-1.46075630e+01,  3.15985894e+00, -1.71326790e+01],\n",
       "         [-1.46692896e+01,  2.96540213e+00, -1.69392624e+01],\n",
       "         [-1.47504606e+01,  2.85064578e+00, -1.67707119e+01],\n",
       "         [-1.47509871e+01,  2.73856831e+00, -1.66935654e+01],\n",
       "         [-1.46947241e+01,  2.67126179e+00, -1.66950455e+01],\n",
       "         [-1.45459871e+01,  2.60950303e+00, -1.67432232e+01],\n",
       "         [-1.44181557e+01,  2.58965135e+00, -1.67323360e+01],\n",
       "         [-1.44125671e+01,  2.60605240e+00, -1.66376476e+01],\n",
       "         [-1.44792414e+01,  2.72750616e+00, -1.65360203e+01],\n",
       "         [-1.45232315e+01,  3.05522680e+00, -1.65412540e+01],\n",
       "         [-1.45068913e+01,  3.41498137e+00, -1.66409054e+01],\n",
       "         [-1.44653845e+01,  3.56308746e+00, -1.67190228e+01],\n",
       "         [-1.44041042e+01,  3.40811825e+00, -1.67154541e+01],\n",
       "         [-1.43906574e+01,  3.12806320e+00, -1.66701794e+01],\n",
       "         [-1.44532051e+01,  2.84040475e+00, -1.66009083e+01],\n",
       "         [-1.45891390e+01,  2.68170905e+00, -1.65746708e+01],\n",
       "         [-1.47441673e+01,  2.73286343e+00, -1.65605831e+01],\n",
       "         [-1.48547096e+01,  2.82611799e+00, -1.65673466e+01],\n",
       "         [-1.48926916e+01,  2.82618523e+00, -1.66261044e+01],\n",
       "         [-1.48447676e+01,  2.81168079e+00, -1.67015476e+01],\n",
       "         [-1.47305517e+01,  2.81613684e+00, -1.67576199e+01],\n",
       "         [-1.46326551e+01,  2.86241269e+00, -1.67595940e+01]],\n",
       " \n",
       "        [[-1.90958691e+01, -1.66454525e+01, -7.40629971e-01],\n",
       "         [-1.90286770e+01, -1.64662800e+01, -1.23020113e+00],\n",
       "         [-1.89688282e+01, -1.61739731e+01, -1.70927787e+00],\n",
       "         [-1.89299450e+01, -1.60046444e+01, -1.77187443e+00],\n",
       "         [-1.89131374e+01, -1.61135921e+01, -1.33077896e+00],\n",
       "         [-1.89276142e+01, -1.64217358e+01, -6.52271688e-01],\n",
       "         [-1.89321003e+01, -1.67206650e+01, -1.32964686e-01],\n",
       "         [-1.89794464e+01, -1.68406963e+01,  3.81569378e-03],\n",
       "         [-1.90866184e+01, -1.67210217e+01, -2.75165051e-01],\n",
       "         [-1.91862602e+01, -1.64947262e+01, -7.20577180e-01],\n",
       "         [-1.92592106e+01, -1.63235378e+01, -1.13187015e+00],\n",
       "         [-1.92923603e+01, -1.63455849e+01, -1.26698363e+00],\n",
       "         [-1.92223568e+01, -1.65549889e+01, -1.15965462e+00],\n",
       "         [-1.91089840e+01, -1.68400936e+01, -9.70102668e-01],\n",
       "         [-1.90757599e+01, -1.69905300e+01, -8.77874434e-01],\n",
       "         [-1.91611080e+01, -1.69721012e+01, -8.53628814e-01],\n",
       "         [-1.92912502e+01, -1.68390255e+01, -8.05489838e-01],\n",
       "         [-1.93544044e+01, -1.67233601e+01, -6.51238739e-01],\n",
       "         [-1.93943443e+01, -1.67504539e+01, -2.91844219e-01],\n",
       "         [-1.94311409e+01, -1.69105854e+01,  1.50194928e-01],\n",
       "         [-1.94569340e+01, -1.71167889e+01,  5.18607557e-01],\n",
       "         [-1.51346960e+01,  2.69279242e+00, -1.70192661e+01],\n",
       "         [-1.52089653e+01,  2.91244841e+00, -1.71414356e+01],\n",
       "         [-1.51912956e+01,  3.37708282e+00, -1.73740425e+01],\n",
       "         [-1.50981216e+01,  3.86412764e+00, -1.75907078e+01],\n",
       "         [-1.49312677e+01,  4.25162220e+00, -1.77721539e+01],\n",
       "         [-1.47953043e+01,  4.39011431e+00, -1.78743649e+01],\n",
       "         [-1.47966814e+01,  4.25053692e+00, -1.78664856e+01],\n",
       "         [-1.49323645e+01,  3.92087650e+00, -1.77203140e+01],\n",
       "         [-1.51200247e+01,  3.52464461e+00, -1.75195656e+01],\n",
       "         [-1.52456999e+01,  3.23267031e+00, -1.73563747e+01],\n",
       "         [-1.52456293e+01,  3.13158751e+00, -1.72932835e+01],\n",
       "         [-1.51163855e+01,  3.28385544e+00, -1.73629570e+01],\n",
       "         [-1.49773712e+01,  3.60928440e+00, -1.75246601e+01],\n",
       "         [-1.49268541e+01,  3.91787505e+00, -1.76382236e+01],\n",
       "         [-1.49723740e+01,  4.12142324e+00, -1.76619930e+01],\n",
       "         [-1.50810452e+01,  4.14940596e+00, -1.76059742e+01],\n",
       "         [-1.51340513e+01,  4.08401918e+00, -1.75217781e+01],\n",
       "         [-1.50190096e+01,  3.93593168e+00, -1.74874916e+01],\n",
       "         [-1.48027611e+01,  3.75436068e+00, -1.74982910e+01],\n",
       "         [-1.46273928e+01,  3.59453940e+00, -1.75526009e+01],\n",
       "         [-1.46046286e+01,  3.49745011e+00, -1.76166668e+01],\n",
       "         [-1.47226553e+01,  3.46368074e+00, -1.76000290e+01],\n",
       "         [-1.48670759e+01,  3.54198647e+00, -1.75642071e+01],\n",
       "         [-1.49514170e+01,  3.73121476e+00, -1.75458241e+01],\n",
       "         [-1.49555054e+01,  3.93889475e+00, -1.75274105e+01],\n",
       "         [-1.48842201e+01,  4.16818714e+00, -1.75265789e+01],\n",
       "         [-1.48263035e+01,  4.35905647e+00, -1.75423489e+01],\n",
       "         [-1.48609629e+01,  4.34561157e+00, -1.74935837e+01],\n",
       "         [-1.49625158e+01,  4.14729452e+00, -1.73852024e+01],\n",
       "         [-1.50773592e+01,  3.87303281e+00, -1.72663593e+01],\n",
       "         [-1.51542654e+01,  3.68285704e+00, -1.71857243e+01],\n",
       "         [-1.51997614e+01,  3.67716789e+00, -1.72234535e+01],\n",
       "         [-1.52169094e+01,  3.84312916e+00, -1.73216267e+01],\n",
       "         [-1.51875200e+01,  4.06839800e+00, -1.74501076e+01],\n",
       "         [-1.51399794e+01,  4.26017094e+00, -1.75699043e+01],\n",
       "         [-1.50727339e+01,  4.34829378e+00, -1.76123848e+01],\n",
       "         [-1.50289202e+01,  4.34146023e+00, -1.75649471e+01],\n",
       "         [-1.49926691e+01,  4.29361200e+00, -1.75192471e+01],\n",
       "         [-1.49365358e+01,  4.31492186e+00, -1.76207314e+01],\n",
       "         [-1.48897390e+01,  4.42118025e+00, -1.78572407e+01],\n",
       "         [-1.48534718e+01,  4.55579472e+00, -1.81217365e+01],\n",
       "         [-1.48166685e+01,  4.67508507e+00, -1.82856236e+01],\n",
       "         [-1.47532444e+01,  4.73168659e+00, -1.82440796e+01],\n",
       "         [-1.46581564e+01,  4.75206041e+00, -1.80253620e+01],\n",
       "         [-1.45445089e+01,  4.69152403e+00, -1.77410049e+01],\n",
       "         [-1.44686985e+01,  4.55361462e+00, -1.75036373e+01],\n",
       "         [-1.44696379e+01,  4.42155600e+00, -1.73950634e+01],\n",
       "         [-1.45521536e+01,  4.32626295e+00, -1.74383678e+01],\n",
       "         [-1.46527939e+01,  4.23223448e+00, -1.75177650e+01],\n",
       "         [-1.47799263e+01,  4.15790367e+00, -1.75681286e+01],\n",
       "         [-1.48451462e+01,  4.14275217e+00, -1.75952244e+01],\n",
       "         [-1.48186731e+01,  4.24756718e+00, -1.76448269e+01],\n",
       "         [-1.47791538e+01,  4.42443991e+00, -1.77509556e+01],\n",
       "         [-1.47255869e+01,  4.58902311e+00, -1.78750648e+01],\n",
       "         [-1.46657686e+01,  4.57847023e+00, -1.79629288e+01],\n",
       "         [-1.46084805e+01,  4.33408213e+00, -1.79712944e+01],\n",
       "         [-1.45699501e+01,  3.97140074e+00, -1.78824291e+01],\n",
       "         [-1.45722742e+01,  3.64307809e+00, -1.76959686e+01],\n",
       "         [-1.46340055e+01,  3.41223478e+00, -1.74992886e+01],\n",
       "         [-1.47184820e+01,  3.30928516e+00, -1.73503742e+01],\n",
       "         [-1.47058296e+01,  3.23463869e+00, -1.73048344e+01],\n",
       "         [-1.46320677e+01,  3.17718482e+00, -1.73352680e+01],\n",
       "         [-1.45099478e+01,  3.11319089e+00, -1.73745518e+01],\n",
       "         [-1.43909655e+01,  3.07793498e+00, -1.73669643e+01],\n",
       "         [-1.43999853e+01,  3.08773708e+00, -1.72845860e+01],\n",
       "         [-1.44771204e+01,  3.18382955e+00, -1.71813946e+01],\n",
       "         [-1.45324945e+01,  3.48534346e+00, -1.71546726e+01],\n",
       "         [-1.45292883e+01,  3.83179450e+00, -1.72289410e+01],\n",
       "         [-1.44938288e+01,  3.96724176e+00, -1.73139915e+01],\n",
       "         [-1.44336166e+01,  3.81797266e+00, -1.73210621e+01],\n",
       "         [-1.44250097e+01,  3.57296658e+00, -1.72682343e+01],\n",
       "         [-1.44721069e+01,  3.31526732e+00, -1.72109699e+01],\n",
       "         [-1.45742559e+01,  3.14644551e+00, -1.71868687e+01],\n",
       "         [-1.46886292e+01,  3.18643761e+00, -1.71798344e+01],\n",
       "         [-1.47876205e+01,  3.26604009e+00, -1.71922855e+01],\n",
       "         [-1.48412275e+01,  3.27016830e+00, -1.72441044e+01],\n",
       "         [-1.48056612e+01,  3.26916933e+00, -1.73253860e+01],\n",
       "         [-1.47124739e+01,  3.28140783e+00, -1.73762836e+01],\n",
       "         [-1.46258707e+01,  3.34022903e+00, -1.73620911e+01]],\n",
       " \n",
       "        [[-1.71576481e+01,  1.16156588e+01, -1.86202469e+01],\n",
       "         [-1.72958775e+01,  1.10495939e+01, -1.87250996e+01],\n",
       "         [-1.91551971e+01, -2.01731396e+01,  8.49854851e+00],\n",
       "         [-1.67870655e+01,  1.09073610e+01, -1.82952557e+01],\n",
       "         [-1.70120354e+01,  1.15467978e+01, -1.85169277e+01],\n",
       "         [-1.67403202e+01,  1.20270271e+01, -1.87751808e+01],\n",
       "         [-1.59316549e+01,  1.26003571e+01, -1.85218983e+01],\n",
       "         [-1.65589714e+01,  1.23069000e+01, -1.81948185e+01],\n",
       "         [-1.72115040e+01,  1.16785526e+01, -1.85761662e+01],\n",
       "         [-1.63061352e+01,  1.34772758e+01, -1.86853752e+01],\n",
       "         [-1.68087654e+01,  1.26941681e+01, -1.87948627e+01],\n",
       "         [-1.71076870e+01,  1.20707455e+01, -1.85862446e+01],\n",
       "         [-1.64691029e+01,  1.31757174e+01, -1.81339931e+01],\n",
       "         [-1.75057812e+01,  1.13479128e+01, -1.84208088e+01],\n",
       "         [-1.68707237e+01,  1.27962093e+01, -1.86262398e+01],\n",
       "         [-1.76409588e+01,  1.12232418e+01, -1.82575302e+01],\n",
       "         [-1.73503590e+01,  1.21476851e+01, -1.84120159e+01],\n",
       "         [-1.72424030e+01,  1.19639120e+01, -1.85025883e+01],\n",
       "         [-1.70883007e+01,  1.28840637e+01, -1.82058659e+01],\n",
       "         [-1.76963444e+01,  1.21906128e+01, -1.82921619e+01],\n",
       "         [-1.95052662e+01, -1.98392563e+01,  1.02363615e+01],\n",
       "         [-1.75985165e+01,  1.19340820e+01, -1.79062309e+01],\n",
       "         [-1.72517338e+01,  1.24050293e+01, -1.84496918e+01],\n",
       "         [-1.73915596e+01,  1.18612900e+01, -1.85483799e+01],\n",
       "         [-1.96142235e+01, -1.99292336e+01,  9.45691872e+00],\n",
       "         [-1.65373535e+01,  1.38607826e+01, -1.86542969e+01],\n",
       "         [-1.68046589e+01,  1.31911030e+01, -1.84991302e+01],\n",
       "         [-1.71084309e+01,  1.23910122e+01, -1.88789387e+01],\n",
       "         [-1.97575588e+01, -1.98384838e+01,  9.21517563e+00],\n",
       "         [-1.65446968e+01,  1.27824154e+01, -1.89786568e+01],\n",
       "         [-1.71801472e+01,  1.23639107e+01, -1.87822361e+01],\n",
       "         [-1.74064865e+01,  1.16834106e+01, -1.85902672e+01],\n",
       "         [-1.66650429e+01,  1.22436714e+01, -1.87952366e+01],\n",
       "         [-1.75792961e+01,  1.25736065e+01, -1.83860302e+01],\n",
       "         [-1.71441441e+01,  1.28326473e+01, -1.86374798e+01],\n",
       "         [-1.75670223e+01,  1.18525085e+01, -1.86253414e+01],\n",
       "         [-1.53843317e+01,  3.87355709e+00, -1.71542377e+01],\n",
       "         [-1.54224758e+01,  3.80184793e+00, -1.70622940e+01],\n",
       "         [-1.53013163e+01,  3.63467598e+00, -1.70093441e+01],\n",
       "         [-1.51028013e+01,  3.44253516e+00, -1.70002308e+01],\n",
       "         [-1.49066191e+01,  3.28514433e+00, -1.70619736e+01],\n",
       "         [-1.48889933e+01,  3.16457319e+00, -1.71305485e+01],\n",
       "         [-1.50168457e+01,  3.12960911e+00, -1.71306839e+01],\n",
       "         [-1.51741848e+01,  3.21976089e+00, -1.71056385e+01],\n",
       "         [-1.52633429e+01,  3.43483758e+00, -1.70943432e+01],\n",
       "         [-1.52809162e+01,  3.67690492e+00, -1.70566788e+01],\n",
       "         [-1.51975031e+01,  3.92335510e+00, -1.70661602e+01],\n",
       "         [-1.51131668e+01,  4.15921021e+00, -1.70938931e+01],\n",
       "         [-1.51415329e+01,  4.15598679e+00, -1.70656281e+01],\n",
       "         [-1.52625132e+01,  3.94450617e+00, -1.69527779e+01],\n",
       "         [-1.53929377e+01,  3.62638164e+00, -1.67906113e+01],\n",
       "         [-1.54833469e+01,  3.43080235e+00, -1.66922932e+01],\n",
       "         [-1.55437908e+01,  3.43141747e+00, -1.67057552e+01],\n",
       "         [-1.55591803e+01,  3.58161736e+00, -1.68161774e+01],\n",
       "         [-1.55417051e+01,  3.81806254e+00, -1.69619598e+01],\n",
       "         [-1.54767876e+01,  4.01325417e+00, -1.71048679e+01],\n",
       "         [-1.53971758e+01,  4.11430883e+00, -1.71643925e+01],\n",
       "         [-1.53722458e+01,  4.11524725e+00, -1.70992794e+01],\n",
       "         [-1.53315668e+01,  4.06506586e+00, -1.70670242e+01],\n",
       "         [-1.52811861e+01,  4.09500790e+00, -1.71853924e+01],\n",
       "         [-1.52164202e+01,  4.20505667e+00, -1.74621162e+01],\n",
       "         [-1.51752901e+01,  4.39024878e+00, -1.77723808e+01],\n",
       "         [-1.51198893e+01,  4.52122545e+00, -1.79585266e+01],\n",
       "         [-1.50422392e+01,  4.59017181e+00, -1.79115582e+01],\n",
       "         [-1.49281149e+01,  4.58116770e+00, -1.76710262e+01],\n",
       "         [-1.48002701e+01,  4.52712250e+00, -1.73442421e+01],\n",
       "         [-1.47393465e+01,  4.37077951e+00, -1.70509014e+01],\n",
       "         [-1.46709042e+01,  5.47107601e+00, -1.73205719e+01],\n",
       "         [-1.48016424e+01,  5.27781010e+00, -1.73505077e+01],\n",
       "         [-1.50399561e+01,  3.94545174e+00, -1.69872494e+01],\n",
       "         [-1.51609287e+01,  3.86114502e+00, -1.70474052e+01],\n",
       "         [-1.52153158e+01,  3.85618830e+00, -1.70823708e+01],\n",
       "         [-1.51930494e+01,  3.99624252e+00, -1.71639118e+01],\n",
       "         [-1.51300287e+01,  4.21880579e+00, -1.73124065e+01],\n",
       "         [-1.50444517e+01,  4.39164019e+00, -1.74509296e+01],\n",
       "         [-1.49756517e+01,  4.35657358e+00, -1.75469589e+01],\n",
       "         [-1.49240255e+01,  4.07184649e+00, -1.75382462e+01],\n",
       "         [-1.48963289e+01,  3.67560363e+00, -1.74250355e+01],\n",
       "         [-1.49171915e+01,  3.33494568e+00, -1.72039223e+01],\n",
       "         [-1.49781828e+01,  3.12625813e+00, -1.70170269e+01],\n",
       "         [-1.50550308e+01,  3.00626421e+00, -1.68564987e+01],\n",
       "         [-1.50506411e+01,  2.88844848e+00, -1.67769833e+01],\n",
       "         [-1.49960566e+01,  2.83439946e+00, -1.67704315e+01],\n",
       "         [-1.48430977e+01,  2.77174187e+00, -1.67983398e+01],\n",
       "         [-1.47082462e+01,  2.74875164e+00, -1.67854671e+01],\n",
       "         [-1.46956291e+01,  2.77234793e+00, -1.66943264e+01],\n",
       "         [-1.47510967e+01,  2.88444710e+00, -1.65996246e+01],\n",
       "         [-1.48098841e+01,  3.22477818e+00, -1.66044159e+01],\n",
       "         [-1.47952909e+01,  3.59217191e+00, -1.67004871e+01],\n",
       "         [-1.47531023e+01,  3.75204921e+00, -1.67785435e+01],\n",
       "         [-1.46948290e+01,  3.59065080e+00, -1.67697029e+01],\n",
       "         [-1.46798792e+01,  3.29430819e+00, -1.67241917e+01],\n",
       "         [-1.47510452e+01,  2.99883485e+00, -1.66588097e+01],\n",
       "         [-1.48931923e+01,  2.83050585e+00, -1.66317883e+01],\n",
       "         [-1.50537205e+01,  2.89437675e+00, -1.66046810e+01],\n",
       "         [-1.51743917e+01,  2.98814988e+00, -1.66066799e+01],\n",
       "         [-1.52038374e+01,  2.99055076e+00, -1.66672421e+01],\n",
       "         [-1.51488514e+01,  2.97048807e+00, -1.67467136e+01],\n",
       "         [-1.50339146e+01,  2.97152162e+00, -1.68022823e+01],\n",
       "         [-1.49227810e+01,  3.02084446e+00, -1.68182926e+01]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 100), dtype=int64, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "         1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model([(\"dunningkruger\", \"eeeeeeeeeeeeeeeeeeeee\", \"thequickbrownfoxjumpedoverthelazydog\"),(None,None, None)])\n",
    "preds, tf.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.pos_embedding(tokenizer([\"e\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.pos_embedding(tokenizer([\"d\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "a = [print(x) for x in model.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c2409f7cd36a60864259fe7c86cc6f7edd5e2a0604f36f600c4aba8b227f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
