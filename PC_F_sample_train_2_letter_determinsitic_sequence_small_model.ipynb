{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:14:00.285123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 17:14:00.438769: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-21 17:14:00.476157: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-21 17:14:01.122097: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-21 17:14:01.122155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-21 17:14:01.122161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'5555545 5555555445 5555445 545 5555545 555545 55555445 545 545 545 555545 5545 55555445 5555445 555545 55555555545 4', shape=(), dtype=string)\n",
      "tf.Tensor(b'55545 5545 5545 45 555445 5445 45 5555555555545 545 555545 545 45 55545 55555545 55555545 545 45 45 445 45 55545 55555555', shape=(), dtype=string)\n",
      "tf.Tensor(b'5555544445 45 55555545 45 5555445 555555545 555555555555555555545 555445 5555555545 5555545 5545 545 5445 45 45 444', shape=(), dtype=string)\n",
      "tf.Tensor(b'545 555555445 555555545 555545 555555545 5555545 5555555555555445 45 45 555545 555545 5555555555555445 555555544', shape=(), dtype=string)\n",
      "tf.Tensor(b'545 5555545 45 555555555445 554445 555545 555555555545 55555545 5545 555545 5555555445 55445 5555545 4445 5445 445 5', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:14:02.145104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 17:14:02.836058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22296 MB memory:  -> device: 3, name: GeForce RTX 3090, pci bus id: 0000:d8:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "GPU_FROM = 3\n",
    "GPU_TO = 4  \n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs visible:{len(visible_devices)}\")\n",
    "tf.config.set_visible_devices(visible_devices[GPU_FROM:GPU_TO],'GPU')\n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs to be used: {len(visible_devices)}\")\n",
    "\n",
    "\n",
    "from segmentation.model import SpaceSegmentationTransformer\n",
    "from segmentation.model import LossWithVoids\n",
    "\n",
    "data = tf.random.stateless_binomial(shape=(10000, 100), counts=1, probs=0.8, seed=[1997,1997])\n",
    "train_frac = int(data.shape[0]*3/4)\n",
    "\n",
    "train_ds, val_ds = tf.data.Dataset.from_tensor_slices(data[:train_frac]), tf.data.Dataset.from_tensor_slices(data[train_frac:])\n",
    "\n",
    "def mapper(y):\n",
    "    x = tf.strings.as_string(y+4)\n",
    "    x = tf.strings.reduce_join(x, axis=-1)\n",
    "    return tf.strings.regex_replace(x, \"(45)\", r\"\\1 \")\n",
    "\n",
    "train_ds = train_ds.map(mapper)\n",
    "val_ds = val_ds.map(mapper)\n",
    "\n",
    "for f in train_ds.take(5):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(), dtype=string, numpy=b'55555455555555445555544554555555455555455555544554554554555554555455555544555554455555'>, None), <tf.Tensor: shape=(100,), dtype=float16, numpy=\n",
      "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
      "        0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1., -1., -1., -1., -1.,\n",
      "       -1., -1., -1., -1., -1., -1., -1., -1., -1.], dtype=float16)>)\n"
     ]
    }
   ],
   "source": [
    "def generate_labels(text):\n",
    "    max_chars = 100\n",
    "\n",
    "    last_char = tf.strings.substr(text, max_chars, max_chars+1)\n",
    "    text = tf.strings.substr(text,0, max_chars)\n",
    "    text = tf.strings.lower(text)\n",
    "    split_on_whitespace = tf.strings.strip(tf.strings.split(text))\n",
    "    encoder_in = tf.strings.reduce_join(split_on_whitespace, axis=-1)\n",
    "    \n",
    "    space_indices = tf.math.cumsum(tf.strings.length(split_on_whitespace)) - 1 # subtract 1 to index from 0\n",
    "    seq_len = space_indices[-1] + 1\n",
    "    if not tf.strings.regex_full_match(last_char, \" \"):\n",
    "        space_indices = space_indices[:-1]\n",
    "    encoder_out = tf.ones((max_chars,))\n",
    "    encoder_out = tf.concat([\n",
    "        tf.ones((seq_len,)),\n",
    "        tf.zeros((max_chars - seq_len,))\n",
    "    ], axis=-1)\n",
    "    encoder_out = tf.tensor_scatter_nd_update(\n",
    "        encoder_out, \n",
    "        space_indices[...,tf.newaxis], # Expand dims to create a 'list' of indices\n",
    "        tf.ones_like(space_indices, dtype=encoder_out.dtype)*2) \n",
    "    \n",
    "    return (encoder_in, None), tf.cast(encoder_out-1, \"float16\")\n",
    "\n",
    "train_ds = train_ds.map(generate_labels)\n",
    "val_ds = val_ds.map(generate_labels)\n",
    "\n",
    "for f in train_ds.take(1):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '5', '4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=100,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "\n",
    "tokenizer.adapt(train_ds.take(10).map(lambda x,y: x[0]))\n",
    "tokenizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"44444455555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpaceSegmentationTransformer(\n",
    "    num_layers=1,\n",
    "    d_model=2,\n",
    "    num_attention_heads=1,\n",
    "    seq_len=100,\n",
    "    dff=5,\n",
    "    input_tokenizer=tokenizer,\n",
    "    dropout_rate=0.1,\n",
    "    num_classes = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.metrics import SparseAccuracyWithIgnore\n",
    "from segmentation.metrics import SparsePrecision\n",
    "from segmentation.metrics import SparseRecall\n",
    "from segmentation.metrics import SparseF1\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, ignore_class=-1), # Why can I not ignore class 0?\n",
    "    metrics=[\n",
    "        SparseAccuracyWithIgnore(ignore_token=-1),\n",
    "        SparsePrecision(class_id=1, name=\"space_precision\"),\n",
    "        SparseRecall(class_id=1, name=\"space_recall\"),\n",
    "        SparseF1(class_id=1, name=\"space_f1\"),\n",
    "        SparsePrecision(class_id=0, name=\"char_precision\"),\n",
    "        SparseRecall(class_id=0, name=\"char_recall\"),\n",
    "        SparseF1(class_id=0, name=\"char_f1\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 11/938 [..............................] - ETA: 15s - loss: 0.7097 - sparse_categorical_accuracy: 0.5007 - space_precision: 0.1310 - space_recall: 0.4843 - space_f1: 0.2062 - char_precision: 0.7282 - char_recall: 0.5037 - char_f1: 0.5955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:14:48.036834: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 23s 21ms/step - loss: 0.4756 - sparse_categorical_accuracy: 0.8255 - space_precision: 0.1357 - space_recall: 0.0284 - space_f1: 0.0470 - char_precision: 0.7304 - char_recall: 0.9717 - char_f1: 0.8339 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8450 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7306 - char_recall: 1.0000 - char_f1: 0.8444 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8454 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.7312 - val_char_recall: 1.0000 - val_char_f1: 0.8447\n",
      "Model: \"space_segmentation_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  67        \n",
      "                                                                 \n",
      " text_vectorization (TextVec  multiple                 0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.shuffle(100).batch(8)\n",
    "val_ds = val_ds.batch(8)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8454 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.7312 - char_recall: 1.0000 - char_f1: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43066439032554626,\n",
       " 0.8454476594924927,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.7312039732933044,\n",
       " 1.0,\n",
       " 0.8447346091270447]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 100, 2), dtype=float32, numpy=\n",
       " array([[[0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997]],\n",
       " \n",
       "        [[0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997]],\n",
       " \n",
       "        [[0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.84615004, 0.15384997],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.8437454 , 0.15625459],\n",
       "         [0.84615004, 0.15384997]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 100), dtype=int64, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model([(\"5554445\", \"55544455554445\", \"5454545454545454\"),(None,None, None)])\n",
    "preds, tf.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c1c312f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(tf.reshape(preds, (-1, 2))[:,0], label=\"prob of char\", range=(0,1))\n",
    "plt.hist(tf.reshape(preds, (-1, 2))[:,1], label=\"prob of space\", range=(0,1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c2409f7cd36a60864259fe7c86cc6f7edd5e2a0604f36f600c4aba8b227f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
