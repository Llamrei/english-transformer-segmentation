{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "   TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
       "  TensorSpec(shape=(None, 100), dtype=tf.float16, name=None)),\n",
       " ((TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "   TensorSpec(shape=(None,), dtype=tf.string, name=None)),\n",
       "  TensorSpec(shape=(None, 100), dtype=tf.float16, name=None)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "GPU_FROM = 0\n",
    "GPU_TO = 1    \n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs visible:{len(visible_devices)}\")\n",
    "tf.config.set_visible_devices(visible_devices[GPU_FROM:GPU_TO],'GPU')\n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs to be used: {len(visible_devices)}\")\n",
    "\n",
    "\n",
    "from segmentation.model import SpaceSegmentationTransformer\n",
    "from segmentation.model import LossWithVoids\n",
    "\n",
    "data = tf.random.stateless_binomial(shape=(10000, 100), counts=1, probs=0.8, seed=[1997,1997]) + 1\n",
    "train_frac = int(data.shape[0]*3/4)\n",
    "\n",
    "train_ds, val_ds = tf.data.Dataset.from_tensor_slices(data[:train_frac]), tf.data.Dataset.from_tensor_slices(data[train_frac:])\n",
    "\n",
    "def mapper(y):\n",
    "    x = tf.strings.as_string(y+4)\n",
    "    x = tf.strings.reduce_join(x, axis=-1)\n",
    "    return (x, x), tf.cast(y, \"float16\")\n",
    "\n",
    "train_ds = train_ds.map(mapper).shuffle(100).batch(8)\n",
    "val_ds = val_ds.map(mapper).batch(8)\n",
    "\n",
    "train_ds.element_spec, val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '6', '5']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=100,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "\n",
    "tokenizer.adapt(train_ds.map(lambda x,y: x[0]))\n",
    "tokenizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"5556665\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpaceSegmentationTransformer(\n",
    "    num_layers=2,\n",
    "    d_model=512,\n",
    "    num_attention_heads=3,\n",
    "    seq_len=100,\n",
    "    dff=1028,\n",
    "    input_tokenizer=tokenizer,\n",
    "    dropout_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.metrics import SparseAccuracyWithIgnore\n",
    "from segmentation.metrics import SparsePrecision\n",
    "from segmentation.metrics import SparseRecall\n",
    "from segmentation.metrics import SparseF1\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # Why can I not ignore class 0?\n",
    "    metrics=[\n",
    "        SparseAccuracyWithIgnore(ignore_token=0.),\n",
    "        SparsePrecision(class_id=2, name=\"space_precision\"),\n",
    "        SparseRecall(class_id=2, name=\"space_recall\"),\n",
    "        SparseF1(class_id=2, name=\"space_f1\"),\n",
    "        SparsePrecision(class_id=1, name=\"char_precision\"),\n",
    "        SparseRecall(class_id=1, name=\"char_recall\"),\n",
    "        SparseF1(class_id=1, name=\"char_f1\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 28s 26ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9976 - space_precision: 0.9989 - space_recall: 0.9983 - space_f1: 0.9986 - char_precision: 0.9952 - char_recall: 0.9946 - char_f1: 0.9949 - val_loss: 3.2685e-07 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 1.0000 - val_char_recall: 1.0000 - val_char_f1: 1.0000\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 3.0366e-07 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 1.0000 - char_recall: 1.0000 - char_f1: 1.0000 - val_loss: 2.7593e-07 - val_sparse_categorical_accuracy: 1.0000 - val_space_precision: 1.0000 - val_space_recall: 1.0000 - val_space_f1: 1.0000 - val_char_precision: 1.0000 - val_char_recall: 1.0000 - val_char_f1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f109d67adf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 2.7593e-07 - sparse_categorical_accuracy: 1.0000 - space_precision: 1.0000 - space_recall: 1.0000 - space_f1: 1.0000 - char_precision: 1.0000 - char_recall: 1.0000 - char_f1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.759265669283195e-07, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 100), dtype=int64, numpy=\n",
       "array([[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model([(\"1111\", \"1212111\", \"222221111\"),(None,None, None)])\n",
    "tf.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c2409f7cd36a60864259fe7c86cc6f7edd5e2a0604f36f600c4aba8b227f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
