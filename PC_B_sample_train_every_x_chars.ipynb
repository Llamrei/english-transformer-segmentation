{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:21:04.417557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 18:21:04.595704: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-20 18:21:04.635340: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-20 18:21:05.356414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-20 18:21:05.356505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-20 18:21:05.356512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "GPU_FROM = 1\n",
    "GPU_TO = 2    \n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs visible:{len(visible_devices)}\")\n",
    "tf.config.set_visible_devices(visible_devices[GPU_FROM:GPU_TO],'GPU')\n",
    "\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "logging.info(f\"Num GPUs to be used: {len(visible_devices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None)), TensorSpec(shape=(100,), dtype=tf.float16, name=None)) ((TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None)), TensorSpec(shape=(100,), dtype=tf.float16, name=None))\n",
      "((<tf.Tensor: shape=(), dtype=string, numpy=b'6666656666666655666665566566666656666656666665566566566566666566656666665566666556666656666666666565'>, <tf.Tensor: shape=(), dtype=string, numpy=b'6666656666666655666665566566666656666656666665566566566566666566656666665566666556666656666666666565'>), <tf.Tensor: shape=(100,), dtype=float16, numpy=\n",
      "array([1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2.,\n",
      "       1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1.,\n",
      "       2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1.,\n",
      "       1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2.,\n",
      "       1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1.,\n",
      "       2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 2., 1., 1.],\n",
      "      dtype=float16)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:21:06.158750: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 18:21:06.839181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22296 MB memory:  -> device: 1, name: GeForce RTX 3090, pci bus id: 0000:5e:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from segmentation.model import SpaceSegmentationTransformer\n",
    "from segmentation.model import LossWithVoids\n",
    "\n",
    "gap = 3\n",
    "len = 100\n",
    "\n",
    "data = tf.random.stateless_binomial(shape=(10000, len), counts=1, probs=0.8, seed=[1997,1997]) + 1\n",
    "train_frac = int(data.shape[0]*3/4)\n",
    "\n",
    "train_ds, val_ds = tf.data.Dataset.from_tensor_slices(data[:train_frac]), tf.data.Dataset.from_tensor_slices(data[train_frac:])\n",
    "\n",
    "def mapper(y):\n",
    "    x = tf.strings.as_string(y+4)\n",
    "    x = tf.strings.reduce_join(x, axis=-1)\n",
    "    # offset_noise = 0\n",
    "    offset_noise =  tf.random.uniform(shape=(), minval=0,maxval=3,dtype=\"int32\")\n",
    "    checkerboard = tf.where((tf.range(len) + offset_noise) % gap == 0, 2, 1)\n",
    "    return (x, x), tf.cast(checkerboard, \"float16\")\n",
    "\n",
    "train_ds = train_ds.map(mapper)\n",
    "val_ds = val_ds.map(mapper)\n",
    "\n",
    "print(train_ds.element_spec, val_ds.element_spec)\n",
    "for x in train_ds.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, <tf.Tensor: shape=(), dtype=float32, numpy=0.75>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SparseAccuracyWithIgnore(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name=\"sparse_categorical_accuracy\", dtype=None, ignore_token=None):\n",
    "        self.ignore_token = ignore_token\n",
    "        super().__init__(name, dtype)\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if self.ignore_token is not None:\n",
    "            mask = tf.not_equal(y_true, tf.cast(self.ignore_token, y_true.dtype))\n",
    "            y_true = tf.boolean_mask(y_true, tf.squeeze(mask))\n",
    "            y_pred = tf.boolean_mask(y_pred, tf.squeeze(mask))\n",
    "            # TODO: Confirm the masking semantics do as we expect\n",
    "            # bit weird it doesn't return a ragged tensor\n",
    "            # Also a bit weird it wasn't a problem before\n",
    "        return super().update_state(y_true, y_pred)\n",
    "\n",
    "m = SparseAccuracyWithIgnore(ignore_token=0)\n",
    "m.update_state(\n",
    "    tf.constant([[1], [2], [1], [1], [0], [0]]),\n",
    "    tf.constant([\n",
    "        [0, 0, 1], # 2 F\n",
    "        [0, 0, 1], # 2 T\n",
    "        [0, 1, 0], # 1 T\n",
    "        [0, 1, 0], # 1 T\n",
    "        [0, 1, 0], # 1 F - should be ignored\n",
    "        [1, 0, 0]  # 0 T - should be ignored\n",
    "    ])\n",
    ")\n",
    "m.ignore_token, m.result() # Wrong is 66% correct is 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '6', '5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=100,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "\n",
    "tokenizer.adapt(train_ds.take(10).map(lambda x,y: x[0]))\n",
    "tokenizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"5556665\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpaceSegmentationTransformer(\n",
    "    num_layers=2,\n",
    "    d_model=512,\n",
    "    num_attention_heads=3,\n",
    "    seq_len=100,\n",
    "    dff=1028,\n",
    "    input_tokenizer=tokenizer,\n",
    "    dropout_rate=0.1,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.metrics import SparseAccuracyWithIgnore\n",
    "from segmentation.metrics import SparsePrecision\n",
    "from segmentation.metrics import SparseRecall\n",
    "from segmentation.metrics import SparseF1\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\n",
    "        SparseAccuracyWithIgnore(ignore_token=0.),\n",
    "        SparsePrecision(class_id=2, name=\"space_precision\"),\n",
    "        SparseRecall(class_id=2, name=\"space_recall\"),\n",
    "        SparseF1(class_id=2, name=\"space_f1\"),\n",
    "        SparsePrecision(class_id=1, name=\"char_precision\"),\n",
    "        SparseRecall(class_id=1, name=\"char_recall\"),\n",
    "        SparseF1(class_id=1, name=\"char_f1\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  7/938 [..............................] - ETA: 20s - loss: 3.6451 - sparse_categorical_accuracy: 0.5045 - space_precision: 0.3367 - space_recall: 0.3713 - space_f1: 0.3532 - char_precision: 0.6659 - char_recall: 0.5712 - char_f1: 0.6149        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 18:21:12.888796: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 29s 26ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6625 - space_precision: 0.3344 - space_recall: 0.0112 - space_f1: 0.0218 - char_precision: 0.6666 - char_recall: 0.9883 - char_f1: 0.7962 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6667 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.6667 - val_char_recall: 1.0000 - val_char_f1: 0.8000\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.6372 - sparse_categorical_accuracy: 0.6666 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.6666 - char_recall: 1.0000 - char_f1: 0.8000 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6666 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.6666 - val_char_recall: 1.0000 - val_char_f1: 0.7999\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.6371 - sparse_categorical_accuracy: 0.6666 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.6666 - char_recall: 1.0000 - char_f1: 0.8000 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6665 - val_space_precision: 0.0000e+00 - val_space_recall: 0.0000e+00 - val_space_f1: nan - val_char_precision: 0.6665 - val_char_recall: 1.0000 - val_char_f1: 0.7999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4fc0d6190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.shuffle(100).batch(8)\n",
    "val_ds = val_ds.batch(8)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_space_precision\",\n",
    "        patience=2,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6365 - sparse_categorical_accuracy: 0.6668 - space_precision: 0.0000e+00 - space_recall: 0.0000e+00 - space_f1: nan - char_precision: 0.6668 - char_recall: 1.0000 - char_f1: 0.8001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6364565491676331,\n",
       " 0.6667519807815552,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.6667519807815552,\n",
       " 1.0,\n",
       " 0.8000614047050476]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 100, 3), dtype=float32, numpy=\n",
       " array([[[9.7392524e-07, 6.6626745e-01, 3.3373156e-01],\n",
       "         [9.7377222e-07, 6.6628414e-01, 3.3371493e-01],\n",
       "         [9.7383486e-07, 6.6628766e-01, 3.3371142e-01],\n",
       "         [9.7399288e-07, 6.6629601e-01, 3.3370301e-01],\n",
       "         [9.7395639e-07, 6.6626978e-01, 3.3372924e-01],\n",
       "         [9.7337386e-07, 6.6631347e-01, 3.3368555e-01],\n",
       "         [9.7337568e-07, 6.6631973e-01, 3.3367929e-01],\n",
       "         [9.7318639e-07, 6.6631335e-01, 3.3368564e-01],\n",
       "         [9.7321004e-07, 6.6631502e-01, 3.3368406e-01],\n",
       "         [9.7328950e-07, 6.6632432e-01, 3.3367473e-01],\n",
       "         [9.7342274e-07, 6.6631764e-01, 3.3368140e-01],\n",
       "         [9.7362306e-07, 6.6630989e-01, 3.3368915e-01],\n",
       "         [9.7375391e-07, 6.6631740e-01, 3.3368161e-01],\n",
       "         [9.7347959e-07, 6.6630763e-01, 3.3369136e-01],\n",
       "         [9.7338807e-07, 6.6629708e-01, 3.3370200e-01],\n",
       "         [9.7319037e-07, 6.6630089e-01, 3.3369818e-01],\n",
       "         [9.7338159e-07, 6.6631871e-01, 3.3368033e-01],\n",
       "         [9.7350357e-07, 6.6631073e-01, 3.3368829e-01],\n",
       "         [9.7357031e-07, 6.6630614e-01, 3.3369285e-01],\n",
       "         [9.7343116e-07, 6.6630566e-01, 3.3369339e-01],\n",
       "         [9.7325346e-07, 6.6631985e-01, 3.3367917e-01],\n",
       "         [9.7334771e-07, 6.6632158e-01, 3.3367747e-01],\n",
       "         [9.7343309e-07, 6.6632849e-01, 3.3367059e-01],\n",
       "         [9.7330451e-07, 6.6633457e-01, 3.3366448e-01],\n",
       "         [9.7360100e-07, 6.6631377e-01, 3.3368522e-01],\n",
       "         [9.7360862e-07, 6.6634309e-01, 3.3365598e-01],\n",
       "         [9.7349925e-07, 6.6633886e-01, 3.3366022e-01],\n",
       "         [9.7342320e-07, 6.6633195e-01, 3.3366710e-01],\n",
       "         [9.7366637e-07, 6.6630965e-01, 3.3368936e-01],\n",
       "         [9.7359282e-07, 6.6632473e-01, 3.3367431e-01],\n",
       "         [9.7328268e-07, 6.6631645e-01, 3.3368257e-01],\n",
       "         [9.7337045e-07, 6.6630977e-01, 3.3368924e-01],\n",
       "         [9.7337522e-07, 6.6632074e-01, 3.3367833e-01],\n",
       "         [9.7321549e-07, 6.6632062e-01, 3.3367842e-01],\n",
       "         [9.7340751e-07, 6.6632622e-01, 3.3367282e-01],\n",
       "         [9.7344400e-07, 6.6632074e-01, 3.3367833e-01],\n",
       "         [9.7344389e-07, 6.6631943e-01, 3.3367962e-01],\n",
       "         [9.7303882e-07, 6.6631275e-01, 3.3368626e-01],\n",
       "         [9.7302677e-07, 6.6630012e-01, 3.3369887e-01],\n",
       "         [9.7301415e-07, 6.6631365e-01, 3.3368534e-01],\n",
       "         [9.7310658e-07, 6.6631722e-01, 3.3368182e-01],\n",
       "         [9.7336761e-07, 6.6631669e-01, 3.3368236e-01],\n",
       "         [9.7345503e-07, 6.6631365e-01, 3.3368543e-01],\n",
       "         [9.7352745e-07, 6.6633528e-01, 3.3366382e-01],\n",
       "         [9.7328689e-07, 6.6632944e-01, 3.3366963e-01],\n",
       "         [9.7297379e-07, 6.6633302e-01, 3.3366603e-01],\n",
       "         [9.7308669e-07, 6.6632390e-01, 3.3367515e-01],\n",
       "         [9.7343946e-07, 6.6631639e-01, 3.3368269e-01],\n",
       "         [9.7362533e-07, 6.6631007e-01, 3.3368894e-01],\n",
       "         [9.7365159e-07, 6.6632307e-01, 3.3367601e-01],\n",
       "         [9.7336567e-07, 6.6632432e-01, 3.3367473e-01],\n",
       "         [9.7328598e-07, 6.6631043e-01, 3.3368859e-01],\n",
       "         [9.7306440e-07, 6.6632515e-01, 3.3367389e-01],\n",
       "         [9.7315819e-07, 6.6633415e-01, 3.3366489e-01],\n",
       "         [9.7320799e-07, 6.6633391e-01, 3.3366519e-01],\n",
       "         [9.7326540e-07, 6.6633952e-01, 3.3365959e-01],\n",
       "         [9.7318980e-07, 6.6631889e-01, 3.3368012e-01],\n",
       "         [9.7316467e-07, 6.6632211e-01, 3.3367696e-01],\n",
       "         [9.7320719e-07, 6.6631305e-01, 3.3368596e-01],\n",
       "         [9.7312261e-07, 6.6631043e-01, 3.3368859e-01],\n",
       "         [9.7315296e-07, 6.6632736e-01, 3.3367166e-01],\n",
       "         [9.7323220e-07, 6.6633582e-01, 3.3366328e-01],\n",
       "         [9.7332997e-07, 6.6632271e-01, 3.3367631e-01],\n",
       "         [9.7336408e-07, 6.6633397e-01, 3.3366507e-01],\n",
       "         [9.7306258e-07, 6.6633475e-01, 3.3366436e-01],\n",
       "         [9.7283669e-07, 6.6631156e-01, 3.3368745e-01],\n",
       "         [9.7308646e-07, 6.6633016e-01, 3.3366892e-01],\n",
       "         [9.7339944e-07, 6.6632199e-01, 3.3367705e-01],\n",
       "         [9.7333589e-07, 6.6632229e-01, 3.3367676e-01],\n",
       "         [9.7349789e-07, 6.6632974e-01, 3.3366933e-01],\n",
       "         [9.7333384e-07, 6.6632158e-01, 3.3367747e-01],\n",
       "         [9.7337499e-07, 6.6632557e-01, 3.3367345e-01],\n",
       "         [9.7336920e-07, 6.6632158e-01, 3.3367747e-01],\n",
       "         [9.7335578e-07, 6.6632581e-01, 3.3367324e-01],\n",
       "         [9.7316547e-07, 6.6630417e-01, 3.3369485e-01],\n",
       "         [9.7321242e-07, 6.6632229e-01, 3.3367676e-01],\n",
       "         [9.7306179e-07, 6.6631830e-01, 3.3368078e-01],\n",
       "         [9.7284021e-07, 6.6631335e-01, 3.3368564e-01],\n",
       "         [9.7269594e-07, 6.6631746e-01, 3.3368152e-01],\n",
       "         [9.7301313e-07, 6.6633070e-01, 3.3366838e-01],\n",
       "         [9.7308782e-07, 6.6632348e-01, 3.3367559e-01],\n",
       "         [9.7280736e-07, 6.6631693e-01, 3.3368215e-01],\n",
       "         [9.7277041e-07, 6.6632336e-01, 3.3367568e-01],\n",
       "         [9.7274233e-07, 6.6632324e-01, 3.3367580e-01],\n",
       "         [9.7312511e-07, 6.6632545e-01, 3.3367357e-01],\n",
       "         [9.7325949e-07, 6.6632348e-01, 3.3367559e-01],\n",
       "         [9.7320401e-07, 6.6632736e-01, 3.3367166e-01],\n",
       "         [9.7339932e-07, 6.6631305e-01, 3.3368596e-01],\n",
       "         [9.7321902e-07, 6.6631925e-01, 3.3367983e-01],\n",
       "         [9.7319514e-07, 6.6633081e-01, 3.3366826e-01],\n",
       "         [9.7318241e-07, 6.6631955e-01, 3.3367950e-01],\n",
       "         [9.7322834e-07, 6.6632879e-01, 3.3367029e-01],\n",
       "         [9.7334373e-07, 6.6631693e-01, 3.3368215e-01],\n",
       "         [9.7343798e-07, 6.6632038e-01, 3.3367866e-01],\n",
       "         [9.7327245e-07, 6.6633868e-01, 3.3366042e-01],\n",
       "         [9.7334373e-07, 6.6632962e-01, 3.3366945e-01],\n",
       "         [9.7321242e-07, 6.6633314e-01, 3.3366594e-01],\n",
       "         [9.7282191e-07, 6.6632688e-01, 3.3367220e-01],\n",
       "         [9.7282214e-07, 6.6633528e-01, 3.3366382e-01],\n",
       "         [9.7294458e-07, 6.6633403e-01, 3.3366498e-01]],\n",
       " \n",
       "        [[9.7377097e-07, 6.6635579e-01, 3.3364329e-01],\n",
       "         [9.7272141e-07, 6.6636801e-01, 3.3363107e-01],\n",
       "         [9.7376699e-07, 6.6636002e-01, 3.3363900e-01],\n",
       "         [9.7284988e-07, 6.6635752e-01, 3.3364156e-01],\n",
       "         [9.7375164e-07, 6.6636038e-01, 3.3363870e-01],\n",
       "         [9.7392012e-07, 6.6634595e-01, 3.3365312e-01],\n",
       "         [9.7389443e-07, 6.6632271e-01, 3.3367631e-01],\n",
       "         [9.7319401e-07, 6.6630471e-01, 3.3369434e-01],\n",
       "         [9.7321242e-07, 6.6631275e-01, 3.3368626e-01],\n",
       "         [9.7311249e-07, 6.6631746e-01, 3.3368152e-01],\n",
       "         [9.7351494e-07, 6.6630954e-01, 3.3368945e-01],\n",
       "         [9.7364773e-07, 6.6630828e-01, 3.3369073e-01],\n",
       "         [9.7370344e-07, 6.6631407e-01, 3.3368501e-01],\n",
       "         [9.7359975e-07, 6.6631168e-01, 3.3368734e-01],\n",
       "         [9.7316718e-07, 6.6631871e-01, 3.3368033e-01],\n",
       "         [9.7328086e-07, 6.6630816e-01, 3.3369082e-01],\n",
       "         [9.7352176e-07, 6.6631418e-01, 3.3368480e-01],\n",
       "         [9.7346185e-07, 6.6631448e-01, 3.3368456e-01],\n",
       "         [9.7346140e-07, 6.6631609e-01, 3.3368289e-01],\n",
       "         [9.7329644e-07, 6.6630745e-01, 3.3369157e-01],\n",
       "         [9.7331633e-07, 6.6632229e-01, 3.3367676e-01],\n",
       "         [9.7333907e-07, 6.6632640e-01, 3.3367261e-01],\n",
       "         [9.7335601e-07, 6.6632402e-01, 3.3367506e-01],\n",
       "         [9.7348209e-07, 6.6633981e-01, 3.3365926e-01],\n",
       "         [9.7357247e-07, 6.6631973e-01, 3.3367929e-01],\n",
       "         [9.7355280e-07, 6.6633612e-01, 3.3366296e-01],\n",
       "         [9.7352438e-07, 6.6633129e-01, 3.3366776e-01],\n",
       "         [9.7334657e-07, 6.6632831e-01, 3.3367071e-01],\n",
       "         [9.7359111e-07, 6.6633314e-01, 3.3366594e-01],\n",
       "         [9.7338364e-07, 6.6633153e-01, 3.3366755e-01],\n",
       "         [9.7323255e-07, 6.6631955e-01, 3.3367950e-01],\n",
       "         [9.7348641e-07, 6.6630024e-01, 3.3369878e-01],\n",
       "         [9.7343479e-07, 6.6631508e-01, 3.3368397e-01],\n",
       "         [9.7320901e-07, 6.6631746e-01, 3.3368152e-01],\n",
       "         [9.7340967e-07, 6.6632074e-01, 3.3367833e-01],\n",
       "         [9.7344196e-07, 6.6631556e-01, 3.3368352e-01],\n",
       "         [9.7346253e-07, 6.6632515e-01, 3.3367389e-01],\n",
       "         [9.7312216e-07, 6.6631585e-01, 3.3368319e-01],\n",
       "         [9.7302006e-07, 6.6631645e-01, 3.3368257e-01],\n",
       "         [9.7324642e-07, 6.6631252e-01, 3.3368650e-01],\n",
       "         [9.7323198e-07, 6.6631603e-01, 3.3368301e-01],\n",
       "         [9.7355769e-07, 6.6632104e-01, 3.3367801e-01],\n",
       "         [9.7360589e-07, 6.6631973e-01, 3.3367929e-01],\n",
       "         [9.7358679e-07, 6.6633260e-01, 3.3366647e-01],\n",
       "         [9.7324789e-07, 6.6634154e-01, 3.3365756e-01],\n",
       "         [9.7305326e-07, 6.6634363e-01, 3.3365545e-01],\n",
       "         [9.7317366e-07, 6.6633070e-01, 3.3366838e-01],\n",
       "         [9.7340899e-07, 6.6631198e-01, 3.3368704e-01],\n",
       "         [9.7366694e-07, 6.6632652e-01, 3.3367252e-01],\n",
       "         [9.7368775e-07, 6.6631722e-01, 3.3368182e-01],\n",
       "         [9.7323277e-07, 6.6632485e-01, 3.3367419e-01],\n",
       "         [9.7313261e-07, 6.6632992e-01, 3.3366913e-01],\n",
       "         [9.7318923e-07, 6.6633058e-01, 3.3366850e-01],\n",
       "         [9.7294333e-07, 6.6633254e-01, 3.3366656e-01],\n",
       "         [9.7322697e-07, 6.6633487e-01, 3.3366424e-01],\n",
       "         [9.7306008e-07, 6.6634768e-01, 3.3365142e-01],\n",
       "         [9.7330246e-07, 6.6632932e-01, 3.3366975e-01],\n",
       "         [9.7307066e-07, 6.6631609e-01, 3.3368289e-01],\n",
       "         [9.7316376e-07, 6.6631252e-01, 3.3368650e-01],\n",
       "         [9.7325778e-07, 6.6630894e-01, 3.3369011e-01],\n",
       "         [9.7322913e-07, 6.6633499e-01, 3.3366403e-01],\n",
       "         [9.7342422e-07, 6.6632879e-01, 3.3367029e-01],\n",
       "         [9.7348413e-07, 6.6633296e-01, 3.3366615e-01],\n",
       "         [9.7336465e-07, 6.6634268e-01, 3.3365640e-01],\n",
       "         [9.7314057e-07, 6.6633415e-01, 3.3366489e-01],\n",
       "         [9.7292116e-07, 6.6633391e-01, 3.3366519e-01],\n",
       "         [9.7325665e-07, 6.6632974e-01, 3.3366933e-01],\n",
       "         [9.7333702e-07, 6.6631871e-01, 3.3368033e-01],\n",
       "         [9.7344230e-07, 6.6632849e-01, 3.3367059e-01],\n",
       "         [9.7348368e-07, 6.6632825e-01, 3.3367082e-01],\n",
       "         [9.7334726e-07, 6.6633457e-01, 3.3366448e-01],\n",
       "         [9.7336704e-07, 6.6632527e-01, 3.3367378e-01],\n",
       "         [9.7319901e-07, 6.6631943e-01, 3.3367962e-01],\n",
       "         [9.7339307e-07, 6.6632015e-01, 3.3367887e-01],\n",
       "         [9.7325506e-07, 6.6631913e-01, 3.3367991e-01],\n",
       "         [9.7314501e-07, 6.6634101e-01, 3.3365810e-01],\n",
       "         [9.7293685e-07, 6.6632116e-01, 3.3367792e-01],\n",
       "         [9.7298550e-07, 6.6630805e-01, 3.3369094e-01],\n",
       "         [9.7288614e-07, 6.6632515e-01, 3.3367389e-01],\n",
       "         [9.7308293e-07, 6.6633028e-01, 3.3366880e-01],\n",
       "         [9.7291047e-07, 6.6633028e-01, 3.3366880e-01],\n",
       "         [9.7283453e-07, 6.6632092e-01, 3.3367813e-01],\n",
       "         [9.7269492e-07, 6.6631871e-01, 3.3368033e-01],\n",
       "         [9.7300142e-07, 6.6632974e-01, 3.3366933e-01],\n",
       "         [9.7328166e-07, 6.6632015e-01, 3.3367887e-01],\n",
       "         [9.7322402e-07, 6.6632015e-01, 3.3367887e-01],\n",
       "         [9.7326665e-07, 6.6633153e-01, 3.3366755e-01],\n",
       "         [9.7323766e-07, 6.6632050e-01, 3.3367854e-01],\n",
       "         [9.7307952e-07, 6.6631269e-01, 3.3368638e-01],\n",
       "         [9.7330314e-07, 6.6632408e-01, 3.3367494e-01],\n",
       "         [9.7315956e-07, 6.6632360e-01, 3.3367547e-01],\n",
       "         [9.7338034e-07, 6.6632736e-01, 3.3367166e-01],\n",
       "         [9.7336670e-07, 6.6631228e-01, 3.3368671e-01],\n",
       "         [9.7345355e-07, 6.6631323e-01, 3.3368576e-01],\n",
       "         [9.7341308e-07, 6.6633707e-01, 3.3366200e-01],\n",
       "         [9.7324346e-07, 6.6633087e-01, 3.3366817e-01],\n",
       "         [9.7313989e-07, 6.6633493e-01, 3.3366412e-01],\n",
       "         [9.7289615e-07, 6.6634279e-01, 3.3365631e-01],\n",
       "         [9.7287420e-07, 6.6633916e-01, 3.3365989e-01],\n",
       "         [9.7297152e-07, 6.6634923e-01, 3.3364981e-01]],\n",
       " \n",
       "        [[9.7390796e-07, 6.6641074e-01, 3.3358833e-01],\n",
       "         [9.7366069e-07, 6.6641819e-01, 3.3358082e-01],\n",
       "         [9.7372197e-07, 6.6641629e-01, 3.3358282e-01],\n",
       "         [9.7391887e-07, 6.6641313e-01, 3.3358592e-01],\n",
       "         [9.7438806e-07, 6.6639596e-01, 3.3360305e-01],\n",
       "         [9.7421525e-07, 6.6639465e-01, 3.3360434e-01],\n",
       "         [9.7288853e-07, 6.6641325e-01, 3.3358580e-01],\n",
       "         [9.7288626e-07, 6.6642302e-01, 3.3357605e-01],\n",
       "         [9.7248790e-07, 6.6642916e-01, 3.3356991e-01],\n",
       "         [9.7262455e-07, 6.6640902e-01, 3.3359003e-01],\n",
       "         [9.7321504e-07, 6.6642708e-01, 3.3357203e-01],\n",
       "         [9.7324266e-07, 6.6641170e-01, 3.3358738e-01],\n",
       "         [9.7366967e-07, 6.6632074e-01, 3.3367833e-01],\n",
       "         [9.7337852e-07, 6.6630131e-01, 3.3369777e-01],\n",
       "         [9.7311056e-07, 6.6632444e-01, 3.3367464e-01],\n",
       "         [9.7329416e-07, 6.6631603e-01, 3.3368301e-01],\n",
       "         [9.7348652e-07, 6.6631871e-01, 3.3368033e-01],\n",
       "         [9.7336454e-07, 6.6632986e-01, 3.3366922e-01],\n",
       "         [9.7362124e-07, 6.6631746e-01, 3.3368152e-01],\n",
       "         [9.7344650e-07, 6.6630977e-01, 3.3368924e-01],\n",
       "         [9.7335214e-07, 6.6632515e-01, 3.3367389e-01],\n",
       "         [9.7342968e-07, 6.6632736e-01, 3.3367166e-01],\n",
       "         [9.7315365e-07, 6.6634309e-01, 3.3365598e-01],\n",
       "         [9.7341660e-07, 6.6633874e-01, 3.3366033e-01],\n",
       "         [9.7359361e-07, 6.6633540e-01, 3.3366361e-01],\n",
       "         [9.7349641e-07, 6.6634512e-01, 3.3365396e-01],\n",
       "         [9.7372447e-07, 6.6635126e-01, 3.3364782e-01],\n",
       "         [9.7368252e-07, 6.6633910e-01, 3.3366001e-01],\n",
       "         [9.7366876e-07, 6.6633224e-01, 3.3366680e-01],\n",
       "         [9.7371890e-07, 6.6633475e-01, 3.3366436e-01],\n",
       "         [9.7345321e-07, 6.6632706e-01, 3.3367199e-01],\n",
       "         [9.7352154e-07, 6.6631407e-01, 3.3368501e-01],\n",
       "         [9.7351824e-07, 6.6631746e-01, 3.3368152e-01],\n",
       "         [9.7320492e-07, 6.6631711e-01, 3.3368194e-01],\n",
       "         [9.7341535e-07, 6.6632783e-01, 3.3367124e-01],\n",
       "         [9.7347970e-07, 6.6632736e-01, 3.3367166e-01],\n",
       "         [9.7347277e-07, 6.6632962e-01, 3.3366945e-01],\n",
       "         [9.7322663e-07, 6.6632253e-01, 3.3367652e-01],\n",
       "         [9.7307918e-07, 6.6631943e-01, 3.3367962e-01],\n",
       "         [9.7323084e-07, 6.6632026e-01, 3.3367875e-01],\n",
       "         [9.7316854e-07, 6.6633046e-01, 3.3366859e-01],\n",
       "         [9.7348914e-07, 6.6632557e-01, 3.3367345e-01],\n",
       "         [9.7354155e-07, 6.6633540e-01, 3.3366361e-01],\n",
       "         [9.7359634e-07, 6.6633981e-01, 3.3365926e-01],\n",
       "         [9.7337750e-07, 6.6634005e-01, 3.3365905e-01],\n",
       "         [9.7300369e-07, 6.6633445e-01, 3.3366466e-01],\n",
       "         [9.7316990e-07, 6.6633391e-01, 3.3366519e-01],\n",
       "         [9.7361908e-07, 6.6632557e-01, 3.3367345e-01],\n",
       "         [9.7367479e-07, 6.6633004e-01, 3.3366901e-01],\n",
       "         [9.7357304e-07, 6.6633153e-01, 3.3366755e-01],\n",
       "         [9.7360703e-07, 6.6632813e-01, 3.3367091e-01],\n",
       "         [9.7320140e-07, 6.6633129e-01, 3.3366776e-01],\n",
       "         [9.7316763e-07, 6.6634059e-01, 3.3365852e-01],\n",
       "         [9.7305383e-07, 6.6633636e-01, 3.3366266e-01],\n",
       "         [9.7331429e-07, 6.6635263e-01, 3.3364645e-01],\n",
       "         [9.7309703e-07, 6.6636533e-01, 3.3363372e-01],\n",
       "         [9.7327506e-07, 6.6635507e-01, 3.3364397e-01],\n",
       "         [9.7298482e-07, 6.6632408e-01, 3.3367494e-01],\n",
       "         [9.7324516e-07, 6.6630530e-01, 3.3369368e-01],\n",
       "         [9.7328052e-07, 6.6633654e-01, 3.3366254e-01],\n",
       "         [9.7318093e-07, 6.6634715e-01, 3.3365196e-01],\n",
       "         [9.7339546e-07, 6.6634470e-01, 3.3365440e-01],\n",
       "         [9.7340933e-07, 6.6633773e-01, 3.3366138e-01],\n",
       "         [9.7332270e-07, 6.6634446e-01, 3.3365461e-01],\n",
       "         [9.7307759e-07, 6.6634375e-01, 3.3365536e-01],\n",
       "         [9.7292047e-07, 6.6633338e-01, 3.3366573e-01],\n",
       "         [9.7314148e-07, 6.6633224e-01, 3.3366680e-01],\n",
       "         [9.7353984e-07, 6.6633677e-01, 3.3366233e-01],\n",
       "         [9.7368741e-07, 6.6632462e-01, 3.3367440e-01],\n",
       "         [9.7373834e-07, 6.6632771e-01, 3.3367133e-01],\n",
       "         [9.7353552e-07, 6.6634524e-01, 3.3365387e-01],\n",
       "         [9.7349027e-07, 6.6634351e-01, 3.3365557e-01],\n",
       "         [9.7316217e-07, 6.6632283e-01, 3.3367622e-01],\n",
       "         [9.7334453e-07, 6.6633773e-01, 3.3366138e-01],\n",
       "         [9.7328837e-07, 6.6634256e-01, 3.3365652e-01],\n",
       "         [9.7331895e-07, 6.6632789e-01, 3.3367112e-01],\n",
       "         [9.7334100e-07, 6.6633666e-01, 3.3366245e-01],\n",
       "         [9.7310897e-07, 6.6632336e-01, 3.3367568e-01],\n",
       "         [9.7279224e-07, 6.6633964e-01, 3.3365947e-01],\n",
       "         [9.7297857e-07, 6.6634774e-01, 3.3365133e-01],\n",
       "         [9.7302791e-07, 6.6633964e-01, 3.3365947e-01],\n",
       "         [9.7252655e-07, 6.6633296e-01, 3.3366615e-01],\n",
       "         [9.7255304e-07, 6.6632634e-01, 3.3367273e-01],\n",
       "         [9.7330656e-07, 6.6633207e-01, 3.3366698e-01],\n",
       "         [9.7309714e-07, 6.6633236e-01, 3.3366668e-01],\n",
       "         [9.7329723e-07, 6.6632962e-01, 3.3366945e-01],\n",
       "         [9.7341672e-07, 6.6632879e-01, 3.3367029e-01],\n",
       "         [9.7333270e-07, 6.6633219e-01, 3.3366689e-01],\n",
       "         [9.7309783e-07, 6.6633540e-01, 3.3366370e-01],\n",
       "         [9.7315615e-07, 6.6633081e-01, 3.3366826e-01],\n",
       "         [9.7311965e-07, 6.6632879e-01, 3.3367029e-01],\n",
       "         [9.7327813e-07, 6.6632855e-01, 3.3367050e-01],\n",
       "         [9.7326244e-07, 6.6633749e-01, 3.3366159e-01],\n",
       "         [9.7319685e-07, 6.6632688e-01, 3.3367220e-01],\n",
       "         [9.7342229e-07, 6.6634011e-01, 3.3365893e-01],\n",
       "         [9.7326210e-07, 6.6635001e-01, 3.3364910e-01],\n",
       "         [9.7325392e-07, 6.6634250e-01, 3.3365661e-01],\n",
       "         [9.7291706e-07, 6.6633868e-01, 3.3366042e-01],\n",
       "         [9.7278473e-07, 6.6632813e-01, 3.3367091e-01],\n",
       "         [9.7309351e-07, 6.6633117e-01, 3.3366793e-01]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 100), dtype=int64, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model([(\"5555a\", \"5656555\", \"555555666666\"),(None,None, None)])\n",
    "preds, tf.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True  True False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [ True  True  True  True  True  True  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]], shape=(3, 100), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "mask = model.encoder.compute_mask(\n",
    "    (\"5555a\", \"5656555\", \"555555666666\")\n",
    ")\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c2409f7cd36a60864259fe7c86cc6f7edd5e2a0604f36f600c4aba8b227f5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
